<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: List of supported learning algorithms.</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">
</head><body>

<table width="100%" summary="page for learners {mlr}"><tr><td>learners {mlr}</td><td align="right">R Documentation</td></tr></table>

<h2>List of supported learning algorithms.</h2>

<h3>Description</h3>


<ul>
<li><p><B>classif.ada</B><br> Boosting from ada package: <code><a href="../../ada/html/ada.html">ada</a></code>
</p>
</li>
<li><p><B>classif.boosting</B><br> Boosting from adabag package: <code><a href="../../adabag/html/boosting.html">boosting</a></code><br>
Note that <code>xval</code> has been set to 0 by default for speed.
</p>
</li>
<li><p><B>classif.blackboost</B><br> Gradient boosting with regression trees from mboost package: <code><a href="../../mboost/html/blackboost.html">blackboost</a></code>
</p>
</li>
<li><p><B>classif.cforest</B><br> Random forest based on conditional inference trees from party package: <code><a href="../../party/html/cforest.html">cforest</a></code>
</p>
</li>
<li><p><B>classif.ctree</B><br> Conditional Inference Trees from party package: <code><a href="../../party/html/ctree.html">ctree</a></code>
</p>
</li>
<li><p><B>classif.fnn</B><br> Fast k-Nearest Neighbor from FNN package: <code><a href="../../FNN/html/knn.html">knn</a></code>
</p>
</li>
<li><p><B>classif.gbm</B><br> Gradient boosting machine from gbm package: <code><a href="../../gbm/html/gbm.html">gbm</a></code>
</p>
</li>
<li><p><B>classif.glmnet</B><br> GLM with lasso or elasticnet regularization from glmnet package: <code><a href="../../glmnet/html/glmnet.html">glmnet</a></code>
</p>
</li>
<li><p><B>classif.geoDA</B><br> Geometric Predictive Discriminant Analysis from DiscriMiner package: <code><a href="../../DiscriMiner/html/geoDA.html">geoDA</a></code>
</p>
</li>
<li><p><B>classif.glmboost</B><br> Boosting for GLMs from mboost package: <code><a href="../../mboost/html/glmboost.html">glmboost</a></code><br>
Note that <code>family</code> has been set to <code>Binomial()</code> by default.
</p>
</li>
<li><p><B>classif.IBk</B><br> K-nearest neighbours from RWeka package: <code><a href="../../RWeka/html/IBk.html">IBk</a></code>
</p>
</li>
<li><p><B>classif.J48</B><br> J48 Decision Trees from RWeka package: <code><a href="../../RWeka/html/J48.html">J48</a></code>
Note that NAs are directly passed to WEKA with <code>na.action = na.pass</code>.
</p>
</li>
<li><p><B>classif.JRip</B><br> Propositional Rule Learner from RWeka package: <code><a href="../../RWeka/html/JRip.html">JRip</a></code>
Note that NAs are directly passed to WEKA with <code>na.action = na.pass</code>.
</p>
</li>
<li><p><B>classif.kknn</B><br> k-Nearest Neighbor from kknn package: <code><a href="../../kknn/html/kknn.html">kknn</a></code>
</p>
</li>
<li><p><B>classif.knn</B><br> k-Nearest Neighbor from class package: <code><a href="../../class/html/knn.html">knn</a></code>
</p>
</li>
<li><p><B>classif.ksvm</B><br> Support Vector Machines from kernlab package: <code><a href="../../kernlab/html/ksvm.html">ksvm</a></code><br>
Note that kernel parameters have to be passed directly and not by using the kpar list in ksvm.<br>
Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>classif.lda</B><br> Linear Discriminant Analysis from MASS package: <code><a href="../../MASS/html/lda.html">lda</a></code>
</p>
</li>
<li><p><B>classif.LiblineaRBinary</B><br> Regularized Binary Linear Predictive Models Estimation from LiblineaR package: <code><a href="../../LiblineaR/html/LiblineaR.html">LiblineaR</a></code>
Note that this model subsumes the types 1,2,3,5
</p>
</li>
<li><p><B>classif.LiblineaRLogReg</B><br> Regularized Logistic Regression from LiblineaR package: <code><a href="../../LiblineaR/html/LiblineaR.html">LiblineaR</a></code>
Note that this model subsumes type 0,6,7.
</p>
</li>
<li><p><B>classif.LiblineaRMultiClass</B><br> Multi-class Support Vector Classification by Crammer and Singer from LiblineaR package: <code><a href="../../LiblineaR/html/LiblineaR.html">LiblineaR</a></code>
Note that this model is type 4.
</p>
</li>
<li><p><B>classif.linDA</B><br> Linear Discriminant Analysis from DiscriMiner package: <code><a href="../../DiscriMiner/html/linDA.html">linDA</a></code>
</p>
</li>
<li><p><B>classif.logreg</B><br> Logistic Regression from stats package: <code><a href="../../stats/html/glm.html">glm</a></code>
</p>
</li>
<li><p><B>classif.lssvm</B><br> Least Squares Support Vector Machine from kernlab package: <code><a href="../../kernlab/html/lssvm.html">lssvm</a></code><br>
Note that <code>fitted</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>classif.lvq1</B><br> Learning Vector Quantization from class package: <code><a href="../../class/html/lvq1.html">lvq1</a></code>
</p>
</li>
<li><p><B>classif.mda</B><br> Mixture Discriminant Analysis from mda package: <code><a href="../../mda/html/mda.html">mda</a></code><br>
Note that <code>keep.fitted</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>classif.multinom</B><br> Multinomial Regression from nnet package: <code><a href="../../nnet/html/multinom.html">multinom</a></code>
</p>
</li>
<li><p><B>classif.naiveBayes</B><br> Naive Bayes from e1071 package: <code><a href="../../e1071/html/naiveBayes.html">naiveBayes</a></code>
</p>
</li>
<li><p><B>classif.nnet</B><br> Neural Network from nnet package: <code><a href="../../nnet/html/nnet.html">nnet</a></code><br>
Note that <code>size</code> has been set to 3 by default.
</p>
</li>
<li><p><B>classif.OneR</B><br> 1-R classifier from RWeka package: <code><a href="../../RWeka/html/OneR.html">OneR</a></code><br>
Note that NAs are directly passed to WEKA with <code>na.action = na.passi</code>.
</p>
</li>
<li><p><B>classif.PART</B><br> PART decision lists from RWeka package: <code><a href="../../RWeka/html/PART.html">PART</a></code><br>
Note that NAs are directly passed to WEKA with <code>na.action = na.pass</code>.
</p>
</li>
<li><p><B>classif.plr</B><br> Logistic regression with a L2 penalty from stepPlr package: <code><a href="../../stepPlr/html/plr.html">plr</a></code><br>
Note that AIC and BIC penalty types can be selected via the new parameter <code>cp.type</code>.
</p>
</li>
<li><p><B>classif.plsDA</B><br> Partial Least Squares (PLS) Discriminant Analysis from DiscriMiner package: <code><a href="../../DiscriMiner/html/plsDA.html">plsDA</a></code>
</p>
</li>
<li><p><B>classif.plsdaCaret</B><br> Partial Least Squares (PLS) Discriminant Analysis from caret package: <code><a href="../../caret/html/plsda.html">plsda</a></code>
</p>
</li>
<li><p><B>classif.qda</B><br> Quadratic Discriminant Analysis from MASS package: <code><a href="../../MASS/html/qda.html">qda</a></code>
</p>
</li>
<li><p><B>classif.quaDA</B><br> Quadratic Discriminant Analysis from DiscriMiner package: <code><a href="../../DiscriMiner/html/quaDA.html">quaDA</a></code>
</p>
</li>
<li><p><B>classif.randomForest</B><br> Random Forest from randomForest package: <code><a href="../../randomForest/html/randomForest.html">randomForest</a></code>.<br>
The argument <code>fix.factors</code> restores the factor levels seen in the training data before prediction to circumvent
randomForest's internal sanity checks. Default is <code>FALSE</code>.
</p>
</li>
<li><p><B>classif.rda</B><br> Regularized Discriminant Analysis from klaR package: <code><a href="../../klaR/html/rda.html">rda</a></code><br>
Note that <code>estimate.error</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>classif.rpart</B><br> Decision Tree from rpart package: <code><a href="../../rpart/html/rpart.html">rpart</a></code><br>
Note that <code>xval</code> has been set to 0 by default for speed.
</p>
</li>
<li><p><B>classif.svm</B><br> Support Vector Machines (libsvm) from e1071 package: <code><a href="../../e1071/html/svm.html">svm</a></code>
</p>
</li></ul>


<ul>
<li><p><B>regr.blackboost</B><br> Gradient boosting with regression trees from mboost package: <code><a href="../../mboost/html/blackboost.html">blackboost</a></code>
</p>
</li>
<li><p><B>regr.cforest</B><br> Random forest based on conditional inference trees from party package: <code><a href="../../party/html/cforest.html">cforest</a></code>
</p>
</li>
<li><p><B>regr.crs</B><br> Regression Splines from crs package: <code><a href="../../crs/html/crs.html">crs</a></code>
</p>
</li>
<li><p><B>regr.earth</B><br> Multivariate Adaptive Regression Splines from earth package: <code><a href="../../earth/html/earth.html">earth</a></code>
</p>
</li>
<li><p><B>regr.fnn</B><br> Fast k-Nearest Neighbor from FNN package: <code><a href="../../FNN/html/knn.html">knn</a></code>
</p>
</li>
<li><p><B>regr.gbm</B><br> Gradient boosting machine from gbm package: <code><a href="../../gbm/html/gbm.html">gbm</a></code><br>
Note that <code>distribution</code> has been set to &ldquo;gaussian&rdquo; by default.
</p>
</li>
<li><p><B>regr.glmnet</B><br> GLM with lasso or elasticnet regularization from glmnet package: <code><a href="../../glmnet/html/glmnet.html">glmnet</a></code>
</p>
</li>
<li><p><B>regr.IBk</B><br> K-nearest neighbours from RWeka package: <code><a href="../../RWeka/html/IBk.html">IBk</a></code>
</p>
</li>
<li><p><B>regr.kknn</B><br> K-Nearest-Neighbor regression from kknn package: <code><a href="../../kknn/html/kknn.html">kknn</a></code>
</p>
</li>
<li><p><B>regr.km</B><br> Kriging from DiceKriging package: <code><a href="../../DiceKriging/html/km.html">km</a></code>
</p>
</li>
<li><p><B>regr.ksvm</B><br> Support Vector Machines from kernlab package: <code><a href="../../kernlab/html/ksvm.html">ksvm</a></code><br>
Note that kernel parameters have to be passed directly and not by using the kpar list in ksvm.<br>
Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>regr.penalized.lasso</B><br> Lasso regression from penalized package: <code><a href="../../penalized/html/penalized.html">penalized</a></code>
</p>
</li>
<li><p><B>regr.lm</B><br> Simple linear regression from stats package: <code><a href="../../stats/html/lm.html">lm</a></code>
</p>
</li>
<li><p><B>regr.mars</B><br> Multivariate Adaptive Regression Splines from mda package: <code><a href="../../mda/html/mars.html">mars</a></code>
</p>
</li>
<li><p><B>regr.mob</B><br> Model-based recursive partitioning  yielding a tree with fitted models associated
with each terminal node from party package: <code><a href="../../party/html/mob.html">mob</a></code>
</p>
</li>
<li><p><B>regr.nnet</B><br> Neural Network from nnet package: <code><a href="../../nnet/html/nnet.html">nnet</a></code><br>
Note that <code>size</code> has been set to 3 by default.
</p>
</li>
<li><p><B>regr.pcr</B><br> Principal component regression from pls package: <code><a href="../../pls/html/pcr.html">pcr</a></code><br>
Note that <code>model</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>regr.randomForest</B><br> Random Forest from randomForest package: <code><a href="../../randomForest/html/randomForest.html">randomForest</a></code>.
The argument <code>fix.factors</code> restores the factor levels seen in the training data before prediction to circumvent
randomForest's internal sanity checks. Default is <code>FALSE</code>.
</p>
</li>
<li><p><B>regr.penalized.ridge</B><br> Ridge regression from penalized package: <code><a href="../../penalized/html/penalized.html">penalized</a></code>
</p>
</li>
<li><p><B>regr.rpart</B><br> Decision Tree from rpart package: <code><a href="../../rpart/html/rpart.html">rpart</a></code><br>
Note that <code>xval</code> has been set to 0 by default for speed.
</p>
</li>
<li><p><B>regr.rsm</B><br> Response surface regression from rsm package: <code><a href="../../rsm/html/rsm.html">rsm</a></code><br>
Note that you select the order of the regression by using modelfun = &quot;FO&quot; (first order), &quot;TWI&quot; (two-way interactions, this is with 1st oder terms!) and &quot;SO&quot; (full second order).
</p>
</li>
<li><p><B>regr.rvm</B><br> Relevance Vector Machine from package kernlab: <code><a href="../../kernlab/html/rvm.html">rvm</a></code><br>
Note that kernel parameters have to be passed directly and not by using the kpar list in rvm.<br>
Note that <code>fit</code> has been set to <code>FALSE</code> by default for speed.
</p>
</li>
<li><p><B>regr.svm</B><br> Support Vector Machines (libsvm) from e1071 package: <code><a href="../../e1071/html/svm.html">svm</a></code>
</p>
</li></ul>


<ul>
<li><p><B>surv.cforest</B><br> Random forest based on conditional inference trees from party package: <code><a href="../../party/html/cforest.html">cforest</a></code>
</p>
</li>
<li><p><B>surv.CoxBoost</B><br> Cox proportional hazards model with componentwise likelhood based boosting from CoxBoost package: <code><a href="../../CoxBoost/html/CoxBoost.html">CoxBoost</a></code>
</p>
</li>
<li><p><B>surv.coxph</B><br> Cox proportional hazard model from survival package: <code><a href="../../survival/html/coxph.html">coxph</a></code>
</p>
</li>
<li><p><B>surv.glmnet</B><br> GLM with regularization from glmnet package: <code><a href="../../glmnet/html/glmnet.html">glmnet</a></code>
</p>
</li>
<li><p><B>surv.randomForestSRC</B><br> Random Forests for Survival from randomForestSRC package: <code><a href="../../randomForestSRC/html/randomForestSRC.html">randomForestSRC</a></code>
</p>
</li></ul>


<ul>
<li><p><B>cluster.SimpleKMeans</B><br> k-means clustering from RWeka package: <code><a href="../../RWeka/html/SimpleKMeans.html">SimpleKMeans</a></code>
</p>
</li>
<li><p><B>cluster.EM</B><br> Expectation-maximization clustering from RWeka package: <code><a href="../../RWeka/html/make_Weka_clusterer.html">make_Weka_clusterer</a></code>
</p>
</li>
<li><p><B>cluster.XMeans</B><br> XMeans (k-means with automatic determination of k) clustering from RWeka package: <code><a href="../../RWeka/html/XMeans.html">XMeans</a></code>
Note that you might have to install the Weka package: <code>WPM("install-package", "XMeans")</code>
</p>
</li></ul>


<hr><div align="center">[Package <em>mlr</em> version 2.1 <a href="00Index.html">Index</a>]</div>
</body></html>
