<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Wraps a classifier for weighted fitting where each class...</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">

<link rel="stylesheet" href="http://yandex.st/highlightjs/7.3/styles/github.min.css">
<script src="http://yandex.st/highlightjs/7.3/highlight.min.js"></script>
<script src="http://yandex.st/highlightjs/7.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for makeWeightedClassesWrapper {mlr}"><tr><td>makeWeightedClassesWrapper {mlr}</td><td align="right">R Documentation</td></tr></table>

<h2>Wraps a classifier for weighted fitting where each class receives a weight.</h2>

<h3>Description</h3>

<p>Creates a wrapper, which can be used like any other learner object.
</p>
<p>Fitting is performed in a weighted fashion where each observation receives a weight,
depending on the class it belongs to, see <code>wcw.weight</code>.
This might help to mitigate problems caused by imbalanced class distributions.
</p>
<p>This weighted fitting can be achieved in two ways:
</p>
<p>a) The learner already has a parameter for class weighting, so one weight can directly be defined
per class. Example: &ldquo;classif.ksvm&rdquo; and parameter <code>class.weights</code>.
In this case we don't really do anything fancy. We convert <code>wcw.weight</code> a bit,
but basically simply bind its value to the class weighting param.
The wrapper in this case simply offers a convenient, consistent fashion for class weighting -
and tuning! See example below.
</p>
<p>b) The learner does not have a direct parameter to support class weighting, but
supports observation weights, so <code>hasProperties(learner, 'weights')</code> is <code>TRUE</code>.
This means that an individual, arbitrary weight can be set per observation during training.
We set this weight depending on the class internally in the wrapper. Basically we introduce
something like a new &ldquo;class.weights&rdquo; parameter for the learner via observation weights.
</p>


<h3>Usage</h3>

<pre>
makeWeightedClassesWrapper(learner, wcw.param = NULL, wcw.weight = 1)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>learner</code></td>
<td>
<p>[<code><a href="makeLearner.html">Learner</a></code> | <code>character(1)</code>]<br>
The classification learner.
If you pass a string the learner will be created via <code><a href="makeLearner.html">makeLearner</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>wcw.param</code></td>
<td>
<p>[<code>character(1)</code>]<br>
Name of already existing learner param which allows class weighting.
Or <code>NULL</code> if such a param does not exist.
Must during training accept a named vector of class weights,
where length equals the number of classes.
Default is <code>NULL</code>.</p>
</td></tr>
<tr valign="top"><td><code>wcw.weight</code></td>
<td>
<p>[<code>numeric</code>]<br>
Weight for each class.
Must be a vector of the same number of elements as classes are in task,
and must also be in the same order as the class levels are in
<code>task$task.desc$class.levels</code>.
For convenience, one must pass a single number in case of binary classification, which
is then taken as the weight of the positive class, while the negative class receives a weight
of 1.
Default is 1.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="makeLearner.html">Learner</a></code>].
</p>


<h3>Examples</h3>

<pre><code class="r"># using the direct parameter of the SVM
lrn = makeWeightedClassesWrapper(&quot;classif.ksvm&quot;, wcw.param = &quot;class.weights&quot;, wcw.weight = 0.01)
res = holdout(lrn, sonar.task)
</code></pre>

<pre><code>## [Resample] holdout iter: 1
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [Resample] Result: mmce.test.mean=0.514
</code></pre>

<pre><code class="r">print(getConfMatrix(res$pred))
</code></pre>

<pre><code>##        predicted
## true    M  R -SUM-
##   M     0 36    36
##   R     0 34     0
##   -SUM- 0 36    36
</code></pre>

<pre><code class="r"># using the observation weights of logreg
lrn = makeWeightedClassesWrapper(&quot;classif.logreg&quot;, wcw.weight = 0.01)
res = holdout(lrn, sonar.task)
</code></pre>

<pre><code>## [Resample] holdout iter: 1
</code></pre>

<pre><code>## Warning: glm.fit: algorithm did not converge
## Warning: glm.fit: fitted probabilities numerically 0 or 1 occurred
</code></pre>

<pre><code>## [Resample] Result: mmce.test.mean=0.386
</code></pre>

<pre><code class="r">print(getConfMatrix(res$pred))
</code></pre>

<pre><code>##        predicted
## true     M  R -SUM-
##   M     21 13    13
##   R     14 22    14
##   -SUM- 14 13    27
</code></pre>

<pre><code class="r"># tuning the imbalancy param and the SVM param in one go
lrn = makeWeightedClassesWrapper(&quot;classif.ksvm&quot;, wcw.param = &quot;class.weights&quot;)
ps = makeParamSet(
  makeNumericParam(&quot;wcw.weight&quot;, lower = 1, upper = 10),
  makeNumericParam(&quot;C&quot;, lower = -12, upper = 12, trafo = function(x) 2^x),
  makeNumericParam(&quot;sigma&quot;, lower = -12, upper = 12, trafo = function(x) 2^x)
)
ctrl = makeTuneControlRandom(maxit = 3L)
rdesc = makeResampleDesc(&quot;CV&quot;, iters = 2L, stratify = TRUE)
res = tuneParams(lrn, sonar.task, rdesc, par.set = ps, control = ctrl)
</code></pre>

<pre><code>## [Tune] Started tuning learner weightedclasses.classif.ksvm for parameter set:
##               Type len Def    Constr Req Trafo
## wcw.weight numeric   -   -   1 to 10   -     -
## C          numeric   -   - -12 to 12   -     Y
## sigma      numeric   -   - -12 to 12   -     Y
## With control class: TuneControlRandom
## Imputation value: 1
## [Tune] 1: wcw.weight=2.36; C=0.916; sigma=32.3 : mmce.test.mean=0.466
## [Tune] 2: wcw.weight=6.68; C=0.973; sigma=2.43e+03 : mmce.test.mean=0.466
## [Tune] 3: wcw.weight=6.06; C=0.122; sigma=0.0155 : mmce.test.mean=0.466
## [Tune] Result: wcw.weight=6.68; C=0.973; sigma=2.43e+03 : mmce.test.mean=0.466
</code></pre>

<pre><code class="r">print(res)
</code></pre>

<pre><code>## Tune result:
## Op. pars: wcw.weight=6.68; C=0.973; sigma=2.43e+03
## mmce.test.mean=0.466
</code></pre>

<pre><code class="r">print(res$opt.path)
</code></pre>

<pre><code>## Optimization path
##   Dimensions: x = 3/3, y = 1
##   Length: 3
##   Add x values transformed: FALSE
##   Error messages: TRUE. Errors: 0 / 3.
##   Exec times: TRUE. Range: 0.076 - 0.08.
</code></pre>


<hr><div align="center">[Package <em>mlr</em> version 2.1 <a href="00Index.html">Index</a>]</div>
</body></html>
