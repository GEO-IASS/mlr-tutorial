<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>R: Fuse learner with feature selection.</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<link rel="stylesheet" type="text/css" href="R.css">

<link rel="stylesheet" href="http://yandex.st/highlightjs/7.3/styles/github.min.css">
<script src="http://yandex.st/highlightjs/7.3/highlight.min.js"></script>
<script src="http://yandex.st/highlightjs/7.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for makeFeatSelWrapper {mlr}"><tr><td>makeFeatSelWrapper {mlr}</td><td align="right">R Documentation</td></tr></table>

<h2>Fuse learner with feature selection.</h2>

<h3>Description</h3>

<p>Fuses a base learner with a search strategy to select variables.
Creates a learner object, which can be used like any other learner object,
but which internally uses <code><a href="selectFeatures.html">selectFeatures</a></code>.
If the train function is called on it,
the search strategy and resampling are invoked to select an optimal set of variables.
Finally, a model is fitted on the complete training data with these variables and returned.
See <code><a href="selectFeatures.html">selectFeatures</a></code> for more details.
</p>
<p>After training, the optimal features (and other related information) can be retrieved with
<code><a href="getFeatSelResult.html">getFeatSelResult</a></code>.
</p>


<h3>Usage</h3>

<pre>
makeFeatSelWrapper(learner, resampling, measures, bit.names, bits.to.features,
  control, show.info = getMlrOption("show.info"))
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>learner</code></td>
<td>
<p>[<code><a href="makeLearner.html">Learner</a></code> | <code>character(1)</code>]<br>
The learner.
If you pass a string the learner will be created via <code><a href="makeLearner.html">makeLearner</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>resampling</code></td>
<td>
<p>[<code><a href="makeResampleInstance.html">ResampleInstance</a></code> | <code><a href="makeResampleDesc.html">ResampleDesc</a></code>]<br>
Resampling strategy for feature selection. If you pass a description,
it is instantiated once at the beginning by default, so all points are evaluated on the same training/test sets.
If you want to change that behaviour, look at <code><a href="FeatSelControl.html">FeatSelControl</a></code>.</p>
</td></tr>
<tr valign="top"><td><code>measures</code></td>
<td>
<p>[list of <code><a href="makeMeasure.html">Measure</a></code> | <code><a href="makeMeasure.html">Measure</a></code>]<br>
Performance measures to evaluate. The first measure, aggregated by the first aggregation function
is optimized, others are simply evaluated.</p>
</td></tr>
<tr valign="top"><td><code>bit.names</code></td>
<td>
<p>[character]<br>
Names of bits encoding the solutions. Also defines the total number of bits in the encoding.
Per default these are the feature names of the task.</p>
</td></tr>
<tr valign="top"><td><code>bits.to.features</code></td>
<td>
<p>[function(x, task)]<br>
Function which transforms an integer-0-1 vector into a character vector of selected features.
Per default a value of 1 in the ith bit selects the ith feature to be in the candidate solution.</p>
</td></tr>
<tr valign="top"><td><code>control</code></td>
<td>
<p>[see <code><a href="FeatSelControl.html">FeatSelControl</a></code>]
Control object for search method.
Also selects the optimization algorithm for feature selection.</p>
</td></tr>
<tr valign="top"><td><code>show.info</code></td>
<td>
<p>[<code>logical(1)</code>]<br>
Print verbose output on console?
Default is set via <code><a href="configureMlr.html">configureMlr</a></code>.</p>
</td></tr>
</table>


<h3>Value</h3>

<p>[<code><a href="makeLearner.html">Learner</a></code>].
</p>


<h3>See Also</h3>

<p>Other featsel: <code><a href="FeatSelControl.html">FeatSelControl</a></code>,
<code><a href="FeatSelControl.html">FeatSelControlExhaustive</a></code>,
<code><a href="FeatSelControl.html">FeatSelControlGA</a></code>,
<code><a href="FeatSelControl.html">FeatSelControlRandom</a></code>,
<code><a href="FeatSelControl.html">FeatSelControlSequential</a></code>,
<code><a href="FeatSelControl.html">makeFeatSelControlExhaustive</a></code>,
<code><a href="FeatSelControl.html">makeFeatSelControlGA</a></code>,
<code><a href="FeatSelControl.html">makeFeatSelControlRandom</a></code>,
<code><a href="FeatSelControl.html">makeFeatSelControlSequential</a></code>;
<code><a href="analyzeFeatSelResult.html">analyzeFeatSelResult</a></code>;
<code><a href="getFeatSelResult.html">getFeatSelResult</a></code>;
<code><a href="selectFeatures.html">selectFeatures</a></code>
</p>


<h3>Examples</h3>

<pre><code class="r"># nested resampling with feature selection (with a pretty stupid algorithm for selection)
outer = makeResampleDesc(&quot;CV&quot;, iters = 2L)
inner = makeResampleDesc(&quot;Holdout&quot;)
ctrl = makeFeatSelControlRandom(maxit = 3)
lrn = makeFeatSelWrapper(&quot;classif.ksvm&quot;, resampling = inner, control = ctrl)
</code></pre>

<pre><code>## Loading required package: kernlab
</code></pre>

<pre><code class="r"># we also extract the selected features for all iteration here
r = resample(lrn, iris.task, outer, extract = getFeatSelResult)
</code></pre>

<pre><code>## [Resample] cross-validation iter: 1
## [FeatSel] Started selecting features for learner &#39;classif.ksvm&#39;
## With control class: FeatSelControlRandom
## Imputation value: 1
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [FeatSel] 1: 2 bits: mmce.test.mean=0.12
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [FeatSel] 1: 1 bits: mmce.test.mean=0.04
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [FeatSel] 1: 4 bits: mmce.test.mean=0.04
## [FeatSel] Result: 4 bits : mmce.test.mean=0.04
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [Resample] cross-validation iter: 2
## [FeatSel] Started selecting features for learner &#39;classif.ksvm&#39;
## With control class: FeatSelControlRandom
## Imputation value: 1
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [FeatSel] 1: 3 bits: mmce.test.mean=0.04
## [FeatSel] 1: 0 bits: mmce.test.mean=0.76
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [FeatSel] 1: 2 bits: mmce.test.mean=0.04
## [FeatSel] Result: 3 bits : mmce.test.mean=0.04
</code></pre>

<pre><code>## Using automatic sigma estimation (sigest) for RBF or laplace kernel
</code></pre>

<pre><code>## [Resample] Result: mmce.test.mean=0.0467
</code></pre>


<hr><div align="center">[Package <em>mlr</em> version 2.1 <a href="00Index.html">Index</a>]</div>
</body></html>
