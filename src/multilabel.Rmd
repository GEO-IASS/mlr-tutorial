# Multilabel Classification

Multilabel classification is a classification problem where multiple target labels can be 
assigned to each observation instead of only one like in multiclass classification. 

Two different approaches exist for multilabel classification. Problem transformation 
methods try to transform the multilabel classification into binary or multiclass 
classification problems. Algorithm adaptation methods adapt multiclass algorithms
so they can be applied directly on the problem. 

## Creating a task
The first thing you have to do for making multilabel classification in [%mlr] is to 
get your data in the right format. You need a [data.frame](&base::data.frame) which 
consists of the features and a logical vector for each label which indicates if the 
label is present in the observation or not. After that you can create a 
[MultilabelTask](task.md) like a normal [ClassifTask](task.md). Instead of one 
target name you have to specify a vector of targets which corresponds to the names of 
logical variables in the [data.frame](&base::data.frame). In the following example 
we get the yeast dataframe from the already existing [yeast.task](&yeast.task) extract 
the 14 label names and create the task again.

```{r}
yeast = getTaskData(yeast.task)
labels = colnames(yeast)[1:14]
yeast.task = makeMultilabelTask(id = "multi", data = yeast, target = labels)
yeast.task
```

## Constructing a learner
Multilabel classification in [&mlr] can currently be done in two ways:

* Use the binary relevance method.
This problem transformation method converts the multilabel problem to binary 
classification problems for each 
label and apply a simple binary classificator on these. In mlr this can be done by 
converting your binary learner to a wrapped binary relevance multilabel learner

* Apply directly a algorithm adaptation method which treats the whole 
problem with a specific algorithm. 

### Binary Relevance Method
For generating a wrapped multilabel learner you must first create a binary (or multiclass) 
classification learner with [makeLearner](&makeLearner). Afterwards you apply the function 
[makeMultilabelBinaryRelevanceWrapper](&makeMultilabelBinaryRelevanceWrapper) on the learner 
to convert it to a binary relevance learner. You can also generate a binary 
relevance learner directly, as you can see in the example. 

```{r}
multilabel.lrn = makeLearner("classif.rpart", predict.type = "prob")
multilabel.lrn = makeMultilabelBinaryRelevanceWrapper(multilabel.lrn)
multilabel.lrn1 = makeMultilabelBinaryRelevanceWrapper("classif.rpart")
multilabel.lrn
```

### Algorithm adaptation method
Currently the only available algorithm adaptation method in **R** is the Random Ferns 
multilabel algorithm in the [%rFerns] package. You can create the learner for this algorithm 
like in multiclass classification problems.

```{r}
multilabel.lrn2 = makeLearner("multilabel.rFerns")
multilabel.lrn2
```

## Train
You can [&train] a model like usual with a multilabel learner and a 
multilabel task as input. You can also pass a ``subset`` and ``weights`` argument if the 
learner supports this. 

```{r}
mod = train(multilabel.lrn, yeast.task)
mod = train(multilabel.lrn, yeast.task, subset = 1:1500, weights = rep(1/1500, 1500))
mod2 = train(multilabel.lrn2, yeast.task, subset = 1:100)
mod

mod2

```

## Predict
Prediction can be done as usual in [&mlr] with [&predict] and by passing a trained model 
and either the trained task to the ``task`` argument or some new data to the ``newdata`` 
argument. In the case of passing a task you can specify a ``subset`` of the task data
which should be predicted. 

```{r}
pred = predict(mod, task = yeast.task, subset = 1:10)
pred = predict(mod, newdata = yeast[1501:1600,])
pred2 = predict(mod2, task = yeast.task)
```

## Performance
The performance of your prediction can be assessed via [&performance]. 
With the ``measures`` argument you can specify the [measure(s)](measures.md). They 
have to be passed as a list. A list of implemented measures for multilabel
can be shown by [listMeasures](&Performance).

```{r}
performance(pred)

performance(pred2, measures = list(hamloss))

listMeasures("multilabel")
```

## Resampling
For evaluating the overall performance of the learning algorithm you can do some 
[resampling](resample.md). Like usual you have to define a resampling strategy 
via the function [&makeResampleDesc]. After that you can run the [&resample] 
function. As default the Hamming Loss is calculated as evaluation measure. 

```{r}
rdesc = makeResampleDesc(method = "CV", stratify = FALSE, iters = 3)
r = resample(learner = multilabel.lrn, task = yeast.task, resampling = rdesc)

r = resample(learner = multilabel.lrn2, task = yeast.task, resampling = rdesc)
```

## Binary Performance
If you want to calculate a binary 
classification measure like e.g. the [accuracy](measures.md), the [mmce](measures.md) 
or the [auc](measures.md) for each label, you can use the function 
[&getMultilabelBinaryPerformances].
You can apply this function on any multilabel prediction e.g. also on the resample 
multilabel prediction. For calculating the [auc](measures.md) you need 
predicted probabilities.

```{r}
getMultilabelBinaryPerformances(pred, measures = list(acc, mmce))

getMultilabelBinaryPerformances(r$pred, measures = list(acc, mmce))
```

