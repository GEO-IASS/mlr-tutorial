# Functional Data

Functional data provides information about curves varying over a continuum, such as time.
This type of data is often present when analyzing measurements at various time points.
Such curves usually are interdependent, which means that the measurement at a point $t_{i + 1}$ usually depends on some measurements ${t_1, ..., t_i}; i \in \mathcal{N}$.

As traditional machine learning techniques usually do not emphasize the interdependence between features,
they are often not _well suited_ for such tasks, which can lead to poor performance.
Functional data analysis on the other hand tries to address this by either using algorithms specifically tailored to functional data, or by transforming the functional covariates into a non time-dependent feature space. 
For a more in depth introduction to functional data analysis see e.g [When the data are functions](http://rd.springer.com/article/10.1007/BF02293704) Ramsay, J.O., 1982. 

Each observation of a functional covariate in the data are evaluations of a functional, i.e. measurements of a scalar value at various time points.
A single observation might then look like this: 
```{r}
# Plot NIR curve for first observarion
library(FDboost)
data(fuelSubset)
library(ggplot2)
# NIR_Obs_1 are the measurements for NIR of the first functional covariate.
# lambda are the time points, the data was measured at.
df = data.frame("NIR_Obs_1" = fuelSubset$NIR[1, ],
                "lambda" = fuelSubset$nir.lambda)
ggplot(df) + 
  geom_line(aes(y = NIR_obs_1, x = lambda))
```

There are two commonly used approaches for analysing functional data.

* Directly analyze the functional data using a [learner](&Learner.md) that is suitable for functional data on a [FDATask](&makeFDATask). Those learners have the prefixes __FDAClassif.__ and __FDARegr.__.

* Transform the task into a format suitable for standard __classification__ or __regression__ [learners](&Learner.md). 
This is done by [extracting](functional_data.Rmd#feature-extraction) non-temporal/non-functional features from the curves. Non-temporal features do not have any interdependence between each other, similarly to features in traditional machine learning.  


## Creating a FDATask

The first step is to get the data into the right format.
[%mlr] expects a  [data.frame](&base::data.frame) which consists of the functional features and the target variable as input. The rows refer to an observation, while columns, such as the set of all columns with index $3, ..., 136$ in the example below correspond to a functional feature.
After coalescing the features to a data.frame, the data object needs to pass into an FDATask, where the data format is defined via _fd.features_ and _fd.grids_. This structure of data is used inside an FDATask, in order to have a clear format for how the data looks like and which measurements correspond to which time point. 
After that a [FDATask](&makeFDATask) that contains the data in the format above was created. [FDATasks](&makeFDATask), just like normal [Tasks](&Task.md) come in different flavours, such as [FDAClassifTask](&makeFDAClassifTask) and [FDARegrTask](&makeFDARegrTask). They can be used according to the class of the target variable.

In the following example, a _Regression Task_ is created for the [fuelSubset](fuelSubset.task) data from package [%FDboost].
The data is provided in the following structure:

```{r}
str(fuelSubset)
```

* __heatan__ is the target variable, in this case a numeric value.
* __h2o__ is an additional scalar variable.
* __NIR__ and __UVVIS__ are matricies containing the curve data. Each column corresponds to a single time point the data was sampled at. Each row indicates a single curve. __NIR__ was measured at $231$ time points, while __UVVIS__ was measured at $129$ time points.
* __nir.lambda__ and __uvvis.lambda__ are vectors of length $231$ and $129$ indicate the time points the data was measured at. Each entry corresponds to one column of __NIR__ and __UVVIS__ respectively.

```{r}
# Plot NIR curve for first observarion
library(ggplot2)
df = data.frame("NIR_obs_1" = fuelSubset$NIR[1, ],
                "lambda" = fuelSubset$nir.lambda)
ggplot(df) + 
  geom_line(aes(y = NIR_obs_1, x = lambda))
```

The [FDATask](&makeFDATask) can then be constructed as follows:

* __fd.features__ is a list of functional features and the associated column indices.
* __fd.grids__ is a list of the functional features' time points, i.e when they were measured. 

```{r}
## Put all values into a data.frame
df = data.frame(fuelSubset[c("heatan", "h2o", "UVVIS", "NIR")])
## Change row names to V1 to V367
colnames(df) = stri_paste("V", 1:367)

## Create a regression task, classification tasks behave analogously
## In this case we use column indices
tsk1 = makeFDARegrTask(data = df, target = "V1", 
  fd.features = list("UVVIS" = 3:136, "NIR" = 137:367),
  fd.grids = list("UVVIS" = fuelSubset$uvvis.lambda,
    "NIR" = fuelSubset$nir.lambda))

## Create a regression task, classification tasks behave analogously
## In this case we use the column names and assume that the data was 
## measured at constant time intervals, thus we do not require 
## setting fd.grids.
tsk2 = makeFDARegrTask(data = df, target = "V1", 
  fd.features = list("UVVIS" = stri_paste("V", 3:136),
    "NIR" = stri_paste("V", 137:367)))
```




## Constructing a learner

For functional data, [learners](&Learner.md) are constructed using 
`makeLearner("<fdaclassif.<R_method_name>")` or 
`makeLearner("<fdaregr.<R_method_name>")` depending on the target variable.

Applying learners to a [FDATask](&makeFDATask) works in two ways:

* Use a [learner](&Learner.md)
that supports functional features, those learners have prefixes  __fdaclassif.__ or __fdaregr.__

  + For regression:
  
  ```{r}
  ## The following learners can be used for the task.
  ## head(listLearners(tsk))
  ## Create a FDboost learner
  fdalrn = makeLearner("fdaregr.FDboost")
  ```
  
  + And for classification:
  
  ```{r}
  ## knn learner
  knn.lrn = makeLearner("fdaclassif.knn")
  ```

* Use a _standard_ [learner](&Learner.md): 
In this case the temporal structure is disregarded

```{r}
## knn learner
lrn = makeLearner("fdaclassif.rpart")
```

* Alternatively, transform the functional data into a non-temporal/non-functional space by [extracting](functional_data.Rmd#feature-extraction) features before training.
In this case, a normal regression- or classification- [learner](&Learner.md) 
can be applied. 
This is explained in more detail in the [feature extraction](functional_data.Rmd#feature-extraction)
section below.


## Train the learner

The resulting learner can now be trained on the task created in section [Creating a FDATask](functional_data.Rmd#creating-a-fdatask) above. 

```{r}
# Train the fdalrn on the FDATask
m = train(learner = fdalrn, task = tsk)
p = predict(m, tsk)
performance(p, rmse)

# Or simply resample (3-fold CV) instead
resample(fdalrn, tsk, resampling = cv3, measures =  mse)
```

Alternatively, learners that do not specifically treat functional covariates can
be applied. In this case the temporal structure is completely disregarded, and all
columns are treated as independent.

```{r}
# Train a normal learner on the FDATask
rpart.lrn = makeLearner("regr.rpart")
m = train(learner = lrn, task = tsk)
```

### Feature Extraction

In contrast to applying a learner that works on a [FDATask](&makeFDATask), the [FDATask](&makeFDATask) can be converted to a normal [&Task.md].
This works by transforming the functional features into a 
non-functional domain, e.g by extracting wavelets.

The currently supported preprocessing functions are:
* discrete wavelet transform
* fast fourier transform
* functional linear array model

The basic structure is `convertFDATaskToNormalTask(task, method, pars)` where the method argument specifies the preprocessing method. This is detailed for wavelets and fourier transfrom in the following sections.

### Wavelets

In this case, discrete wavelet feature transformation is applied.
We can specify which feature extraction method is used via _method = "wavelets"_ and add additional parameters (i.e. the filter and the boundary) in the pars argument. 
This functions returns a regression task of type regr since the raw data contained temporal structure but the transformed data does not inherit temporal structure anymore.
```{r, eval = FALSE}
## Specify the feature extraction method and generate new task.
## Here, we use the Haar filter:
task.w = convertFDATaskToNormalTask(task = tsk, method = "wavelets", pars = list(filter = "haar"))
print(task.w)

# Use the Daubechie wavelet with filter length 4.
task.wd4 = convertFDATaskToNormalTask(task = tsk, method = "wavelets", pars = list(filter = "d4"))
print(task.wd4)
```
The transformation calls the function [&getFDAWaveletFeatures].


### Fourier transformation

Now, we use the fourier feature transformation. Either the amplitude or the phase of the complex fourier coefficients can be used for analysis. This can be specified in the additional _fft.coeff_ argument:

```{r, eval = FALSE}
# Specify the feature extraction method and generate new task.
# We use the fourier features and the amplitude:
task.fa = convertFDATaskToNormalTask(task = tsk, method = "fourier", 
  pars = list(fft.coeff = "amplitude"))
print(task.fa)
# ... or we prefer the phase:
task.fp = convertFDATaskToNormalTask(task = tsk, method = "fourier", 
  pars = list(fft.coeff = "phase"))
print(task.fp)
```

This transformation uses the function [&getFDAFourierFeatures].

