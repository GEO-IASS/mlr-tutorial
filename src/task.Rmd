# Learning Tasks
Learning tasks encapsulate the data set and further relevant information about a machine
learning problem, for example the name of the target variable.


## Task types and creation
The tasks are organized in a hierarchy, with the generic [&Task] at the top.
The following tasks can be instantiated and all inherit from the virtual superclass [&Task]:

* [ClassifTask](&Task) for binary and multi-class classification problems
  (normal cost-sensitive classification can be handled as well),
* [MultilabelTask](&Task) for multilabel classification problems,
* [RegrTask](&Task) for regression problems,
* [SurvTask](&Task) for survival analysis,
* [CostSensTask](&Task) for general cost-sensitive classification
  (with example specific costs),
* [ClusterTask](&Task) for cluster analysis.

To create a task, just call ``make<TaskType>``, e.g., [makeClassifTask](&Task).
All tasks require an identifier (argument ``id``) and a [data.frame](&base::data.frame) (argument ``data``).
If no ID is provided it is automatically generated using the variable name of the data.
It will be later used to name results, for example of
[benchmark experiments](benchmark_experiments.md), or in generated plots.
Depending on the nature of the learning problem, additional arguments may be required and
are discussed in the following subsections.


### Regression
For supervised learning like regression (as well as classification and
survival analysis) we, in addition to ``data``, have to specify the name of the ``target``
variable.

```{r}
data(BostonHousing, package = "mlbench")
regr.task = makeRegrTask(id = "bh", data = BostonHousing, target = "medv")
regr.task
```

As you can see, the [&Task] records the type of the learning problem and basic information about
the data set, e.g., the types of the features (numeric vectors, factors or ordered factors),
the number of observations, or whether missing values are present.

Creating tasks for classification problems and survival analysis follows the same scheme,
the data type of the target variables included in ``data`` is simply different.
For each of these learning problems, some specifics are described below.


### Classification
For classification the target variable has to be a [factor](&base::factor).

In binary classification it is customary to refer to the two classes as *positive* and
*negative* class.
This is for example relevant for certain [performance measures](performance.md)
like the *true positive rate*.
By default the first factor level of the target variable is selected as the positive class.

In the following example, we define a classification task for the
[BreastCancer](&mlbench::BreastCancer) data set and exclude the variable ``Id`` from all further
model fitting and evaluation.

```{r}
data(BreastCancer, package = "mlbench")
df = BreastCancer
df$Id = NULL
classif.task = makeClassifTask(id = "BreastCancer", data = df, target = "Class")
classif.task
```

The positive class is ``benign``.
Class ``malignant`` can be manually selected as the positive class:

```{r}
classif.task = makeClassifTask(id = "BreastCancer", data = df, target = "Class", positive = "malignant")
```

### Multilabel Classification

For multilabel classification the input [data.frame](&base::data.frame) must consist 
of feature vectors and a logical vector for each label. 
The target variable has to be a character vector of targets which represents the labels 
and corresponds to the names of the logical vectors in the [data.frame](&base::data.frame). 

In the following example we get the data of the yeast dataset, extract the labelnames, 
and pass them to the ``target`` argument in [makeMultilabelTask](&makeMultilabelTask). 

```{r}
yeast = getTaskData(yeast.task)
labels = colnames(yeast)[1:14]
yeast.task = makeMultilabelTask(id = "multi", data = yeast, target = labels)
```

### Cluster analysis
As cluster analysis is unsupervised, the only mandatory argument to construct a cluster analysis task is the ``data``.
Below we create a learning task from the data set [mtcars](&datasets::mtcars).

```{r}
data(mtcars, package = "datasets")
cluster.task = makeClusterTask(data = mtcars)
cluster.task
```

### Survival analysis
Survival tasks use two target columns.
For left and right censored problems these consist of the survival time and a binary event indicator.
For interval censored data the two target columns must be specified in the ``"interval2"`` format (see [Surv](&survival::Surv)).

```{r}
data(lung, package = "survival")
lung$status = (lung$status == 2) # convert to logical
surv.task = makeSurvTask(data = lung, target = c("time", "status"))
surv.task
```

The type of censoring can be specified via the argument ``censoring``, which defaults to
``"rcens"`` for right censored data.


### Cost-sensitive classification
The standard objective in classification is to obtain a high prediction accuracy, i.e., to
minimize the number of errors. Thereby, all types of misclassification errors are deemed
equally severe. However, in many applications different kinds of errors cause different costs.

In case of *class-dependent costs*, that depend on the actual and predicted class labels, it
is sufficient to create an ordinary [ClassifTask](&Task).

In order to handle *example-specific costs* it is necessary to generate a [CostSensTask](&Task).
In this scenario, each example $(x, y)$ is associated with an individual cost vector of length
$K$ where $K$ denotes the number of classes. The $k$-th component indicates the cost of assigning
$x$ to class $k$. Naturally, it is assumed that the cost of the intended class label $y$ is
minimal.

As the cost vector contains all relevant information about the intended class label $y$, only
the feature values $x$ and a ``cost`` matrix, which contains the cost vectors for all examples in the data
set, are required to create the [CostSensTask](&Task).

In the following example we use the [iris data](&datasets::iris) and generate an artificial cost matrix
(following [Beygelzimer et al., 2005](http://dx.doi.org/10.1145/1102351.1102358)):

```{r}
df = iris
cost = matrix(runif(150 * 3, 0, 2000), 150) * (1 - diag(3))[df$Species,]
df$Species = NULL

costsens.task = makeCostSensTask(data = df, cost = cost)
costsens.task
```

For more details see the section about [cost-sensitive classification](cost_sensitive_classif.md).


## Further settings
The [&Task] help page also lists several other arguments to describe further details of the
learning problem.

For example, we could include a ``blocking`` factor in the task.
This would tell the task that some observations "belong together" and should
not be separated when splitting into training and test sets during a [resampling](resample.md) iteration.

Another possibility is to assign ``weights`` to observations.
These can for example simply indicate observation frequencies or result from the sampling
scheme used to collect the data.


## Accessing a learning task
We provide many operators to access the elements stored in a [&Task].
The most important ones are listed in the documentation of [&Task] and [&getTaskData].

To access the [task description](&TaskDesc) that contains basic infos about
the task you can use

```{r}
getTaskDescription(classif.task)
```

Note that [task description](&TaskDesc)s have slightly different elements, depending on
the type of the [&Task].
Frequently needed elements can also be accessed directly.
```{r}
## Get the ID
getTaskId(classif.task)

## Get the type of task
getTaskType(classif.task)

## Get the names of the target columns
getTaskTargetNames(classif.task)

## Get the number of observations
getTaskSize(classif.task)

## Get the number of input variables
getTaskNFeats(classif.task)

## Get the class levels in classif.task
getTaskClassLevels(classif.task)
```

Moreover, [%mlr] provides several functions to extract data from a [&Task].
```{r}
## Accessing the data set in classif.task
str(getTaskData(classif.task))

## Get the names of the input variables in cluster.task
getTaskFeatureNames(cluster.task)

## Get the values of the target variable in surv.task
head(getTaskTargets(surv.task))

## Get the cost matrix in costsens.task
head(getTaskCosts(costsens.task))
```

Note the many options that [&getTaskData] offers to convert the data set into a convenient format.
This especially comes in handy when you [integrate a learner](create_learner.md) from another **R**
package into [%mlr].
In this regard function [&getTaskFormula] is also useful.


## Modifying a learning task
[%mlr] provides several functions to alter an existing [&Task], which is often more
convenient than creating a new [&Task] from scratch.
Here are some examples.

```{r}
## Select observations and/or features
cluster.task = subsetTask(cluster.task, subset = 4:17)

## It may happen, especially after selecting observations, that features are constant.
## These should be removed.
removeConstantFeatures(cluster.task)

## Remove selected features
dropFeatures(surv.task, c("meal.cal", "wt.loss"))

## Standardize numerical features
task = normalizeFeatures(cluster.task, method = "range")
summary(getTaskData(task))
```

For more functions and more detailed explanations have a look at the
[data preprocessing](preproc.md) section.


## Example tasks and convenience functions
For your convenience [%mlr] provides pre-defined [Task](&Task)s for each type of learning problem.
These are used throughout this tutorial in order to get shorter and more readable code.
A list of all [Task](&Task)s can be found [here](example_tasks.md).

Moreover, [%mlr]'s function [&convertMLBenchObjToTask] can generate [%mlr] [&Task]s from the data
sets and data generating functions in package [%mlbench].
