<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../img/favicon.ico">

	<title>Cost-Sensitive Classification - mlr tutorial</title>

        <link href="../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../css/font-awesome-4.0.3.css" rel="stylesheet">
        <link href="../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="../css/highlight.css">

        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
        <![endif]-->

        
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
    <div class="container">

        <!-- Collapsed navigation -->
        <div class="navbar-header">
            
            <!-- Expander button -->
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            

            <!-- Main title -->
            <a class="navbar-brand" href="../index.html">mlr tutorial</a>
        </div>

        <!-- Expanded navigation -->
        <div class="navbar-collapse collapse">
            
                <!-- Main navigation -->
                <ul class="nav navbar-nav">
                
                
                    <li >
                        <a href="../index.html">Home</a>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Basics <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../task/index.html">Tasks</a>
</li>

                        
                            
<li >
    <a href="../learner/index.html">Learners</a>
</li>

                        
                            
<li >
    <a href="../train/index.html">Train</a>
</li>

                        
                            
<li >
    <a href="../predict/index.html">Predict</a>
</li>

                        
                            
<li >
    <a href="../performance/index.html">Performance</a>
</li>

                        
                            
<li >
    <a href="../resample/index.html">Resampling</a>
</li>

                        
                            
<li >
    <a href="../benchmark_experiments/index.html">Benchmark Experiments</a>
</li>

                        
                            
<li >
    <a href="../parallelization/index.html">Parallelization</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown active">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Advanced <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../configureMlr/index.html">Configuration</a>
</li>

                        
                            
<li >
    <a href="../wrapper/index.html">Wrapped Learners</a>
</li>

                        
                            
<li >
    <a href="../preproc/index.html">Preprocessing</a>
</li>

                        
                            
<li >
    <a href="../impute/index.html">Imputations</a>
</li>

                        
                            
<li >
    <a href="../bagging/index.html">Bagging</a>
</li>

                        
                            
<li >
    <a href="../tune/index.html">Tuning</a>
</li>

                        
                            
<li >
    <a href="../feature_selection/index.html">Feature Selection</a>
</li>

                        
                            
<li class="active">
    <a href="index.html">Cost-Sensitive Classification</a>
</li>

                        
                            
<li >
    <a href="../over_and_undersampling/index.html">Imbalanced Classification Problems</a>
</li>

                        
                            
<li >
    <a href="../roc_analysis/index.html">ROC Analysis</a>
</li>

                        
                            
<li >
    <a href="../learning_curve/index.html">Learning Curve</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Extend <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../create_learner/index.html">Create Custom Learners</a>
</li>

                        
                            
<li >
    <a href="../create_measure/index.html">Create Custom Measures</a>
</li>

                        
                            
<li >
    <a href="../create_imputation/index.html">Create an Imputation Method</a>
</li>

                        
                        </ul>
                    </li>
                
                
                
                    <li class="dropdown">
                        <a href="#" class="dropdown-toggle" data-toggle="dropdown">Appendix <b class="caret"></b></a>
                        <ul class="dropdown-menu">
                        
                            
<li >
    <a href="../example_tasks/index.html">Example Tasks</a>
</li>

                        
                            
<li >
    <a href="../integrated_learners/index.html">Integrated Learners</a>
</li>

                        
                            
<li >
    <a href="../measures/index.html">Implemented Performance Measures</a>
</li>

                        
                            
<li >
    <a href="../filter_methods/index.html">Integrated Filter Methods</a>
</li>

                        
                        </ul>
                    </li>
                
                
                </ul>
            

            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                        <i class="fa fa-search"></i> Search
                    </a>
                </li>
                
                    <li >
                        <a rel="next" href="../feature_selection/index.html">
                            <i class="fa fa-arrow-left"></i> Previous
                        </a>
                    </li>
                    <li >
                        <a rel="prev" href="../over_and_undersampling/index.html">
                            Next <i class="fa fa-arrow-right"></i>
                        </a>
                    </li>
                
                
                    <li>
                        <a href="https://github.com/berndbischl/mlr/">
                            
                                <i class="fa fa-github"></i>
                            
                            GitHub
                        </a>
                    </li>
                
            </ul>
        </div>
    </div>
</div>

        <div class="container">
            
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
    
        <li class="main active"><a href="#cost-sensitive-classification">Cost-Sensitive Classification</a></li>
        
            <li><a href="#class-dependent-misclassification-costs">Class-dependent misclassification costs</a></li>
        
            <li><a href="#example-dependent-misclassification-costs">Example-dependent misclassification costs</a></li>
        
    
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="cost-sensitive-classification">Cost-Sensitive Classification</h1>
<p>In <em>regular classification</em> the aim is to minimize the misclassification rate and
thus all types of misclassification errors are deemed equally severe.
A more general setting is <em>cost-sensitive classification</em> where the costs caused by different
kinds of errors are not assumed to be equal and the objective is to minimize the expected costs.</p>
<p>In case of <em>class-dependent costs</em> the costs depend on the true and predicted class label.
The costs <script type="math/tex">c(k, l)</script> for predicting class <script type="math/tex">k</script> if the true label is <script type="math/tex">l</script> are usually organized
into a <script type="math/tex">K \times K</script> cost matrix where <script type="math/tex">K</script> is the number of classes.
Naturally, it is assumed that the cost of predicting the correct class label <script type="math/tex">y</script> is minimal
(that is <script type="math/tex">c(y, y)</script> is smaller or equal to <script type="math/tex">c(k, y)</script> for all <script type="math/tex">k</script>).</p>
<p>A further generalization of this scenario are <em>example-dependent misclassification costs</em> where
each example <script type="math/tex">(x, y)</script> is coupled with an individual cost vector of length <script type="math/tex">K</script>. Its <script type="math/tex">k</script>-th
component expresses the cost of assigning <script type="math/tex">x</script> to class <script type="math/tex">k</script>.
A real-world example is fraud detection where the costs do not only depend on the true and
predicted status fraud/non-fraud, but also on the amount of money involved in each case.
Naturally, the cost of predicting the true class label <script type="math/tex">y</script> is assumed to be minimum.
The true class labels are redundant information, as they can be easily inferred from the
cost vectors.
Moreover, given the cost vector, the expected costs do not depend on the true class label <script type="math/tex">y</script>.
The classification problem is therefore completely defined by the feature values <script type="math/tex">x</script> and the
corresponding cost vectors.</p>
<p>In the following we show ways to handle cost-sensitive classification problems in <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a>.
Some of the functionality is currently experimental, and there may be changes in the future.</p>
<h2 id="class-dependent-misclassification-costs">Class-dependent misclassification costs</h2>
<p>There are some classification methods that can accomodate misclassification costs
directly.
One example is <a href="http://www.rdocumentation.org/packages/rpart/functions/rpart.html">rpart</a>.</p>
<p>Alternatively, we can use cost-insensitive methods and manipulate the predictions or the
training data in order to take misclassification costs into account.
<a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> supports <em>thresholding</em> and <em>rebalancing</em>.</p>
<ol>
<li>
<p><strong>Thresholding</strong>:
  The thresholds used to turn posterior probabilities into class labels are chosen such that
  the costs are minimized.
  This requires a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> that can predict posterior probabilities.
  During training the costs are not taken into account.</p>
</li>
<li>
<p><strong>Rebalancing</strong>:
  The idea is to change the proportion of the classes in the training data set in order to
  account for costs during training, either by <em>weighting</em> or by <em>sampling</em>.
  Rebalancing does not require that the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> can predict probabilities.</p>
<p>i. For <em>weighting</em> we need a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> that supports class weights or observation
     weights.</p>
<p>ii. If the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> cannot deal with weights the proportion of classes can
     be changed by <em>over-</em> and <em>undersampling</em>.</p>
</li>
</ol>
<p>We start with binary classification problems and afterwards deal with multi-class problems.</p>
<h3 id="binary-classification-problems">Binary classification problems</h3>
<p>The positive and negative classes are labeled 1 and -1, respectively, and we consider the
following cost matrix where the rows indicate true classes and the columns predicted classes:</p>
<table>
<thead>
<tr>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr>
<td align="center">true\pred.</td>
<td align="center">
<script type="math/tex">+1</script>
</td>
<td align="center">
<script type="math/tex">-1</script>
</td>
</tr>
<tr>
<td align="center">
<script type="math/tex">+1</script>
</td>
<td align="center">
<script type="math/tex">c(+1,+1)</script>
</td>
<td align="center">
<script type="math/tex">c(-1,+1)</script>
</td>
</tr>
<tr>
<td align="center">
<script type="math/tex">-1</script>
</td>
<td align="center">
<script type="math/tex">c(+1,-1)</script>
</td>
<td align="center">
<script type="math/tex">c(-1,-1)</script>
</td>
</tr>
</tbody>
</table>
<p>Often, the diagonal entries are zero or the cost matrix is rescaled to achieve zeros in the diagonal
(see for example <a href="http://machinelearning.org/archive/icml2008/papers/150.pdf">O'Brien et al, 2008</a>).</p>
<p>A well-known cost-sensitive classification problem is posed by the
<a href="http://www.rdocumentation.org/packages/caret/functions/GermanCredit.html">German Credit data set</a>
(see also the <a href="https://archive.ics.uci.edu/ml/datasets/Statlog+(German+Credit+Data)">UCI Machine Learning Repository</a>).
The corresponding cost matrix (though <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a>
argues that this matrix is economically unreasonable) is given as:</p>
<table>
<thead>
<tr>
<th></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr>
<td>true\pred.</td>
<td align="center">Bad</td>
<td align="center">Good</td>
</tr>
<tr>
<td>Bad</td>
<td align="center">0</td>
<td align="center">5</td>
</tr>
<tr>
<td>Good</td>
<td align="center">1</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>As in the table above, the rows indicate true and the columns predicted classes.</p>
<p>For class-dependent costs it is sufficient to generate an ordinary <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">ClassifTask</a>.
A <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">CostSensTask</a> is needed in case of example-dependent costs.
In the following we create the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">ClassifTask</a>, remove two constant features from the
data set and generate the cost matrix.
Per default, Bad is the positive class.</p>
<pre><code class="r">data(GermanCredit, package = &quot;caret&quot;)
credit.task = makeClassifTask(data = GermanCredit, target = &quot;Class&quot;)
credit.task = removeConstantFeatures(credit.task)
#&gt; Removing 2 columns: Purpose.Vacation,Personal.Female.Single
credit.task
#&gt; Supervised task: GermanCredit
#&gt; Type: classif
#&gt; Target: Class
#&gt; Observations: 1000
#&gt; Features:
#&gt; numerics  factors  ordered 
#&gt;       59        0        0 
#&gt; Missings: FALSE
#&gt; Has weights: FALSE
#&gt; Has blocking: FALSE
#&gt; Classes: 2
#&gt;  Bad Good 
#&gt;  300  700 
#&gt; Positive class: Bad

costs = matrix(c(0, 1, 5, 0), 2)
colnames(costs) = rownames(costs) = getTaskDescription(credit.task)$class.levels
costs
#&gt;      Bad Good
#&gt; Bad    0    5
#&gt; Good   1    0
</code></pre>

<h4 id="1-thresholding">1. Thresholding</h4>
<p>We start by fitting a <a href="http://www.rdocumentation.org/packages/nnet/functions/multinom.html">logistic regression model</a> to the
<a href="http://www.rdocumentation.org/packages/caret/functions/GermanCredit.html">German credit data set</a> and predicting posterior probabilities.</p>
<pre><code class="r">## Train and predict posterior probabilities
lrn = makeLearner(&quot;classif.multinom&quot;, predict.type = &quot;prob&quot;, trace = FALSE)
mod = train(lrn, credit.task)
pred = predict(mod, task = credit.task)
pred
#&gt; Prediction: 1000 observations
#&gt; predict.type: prob
#&gt; threshold: Bad=0.50,Good=0.50
#&gt; time: 0.02
#&gt;   id truth   prob.Bad prob.Good response
#&gt; 1  1  Good 0.03525092 0.9647491     Good
#&gt; 2  2   Bad 0.63222363 0.3677764      Bad
#&gt; 3  3  Good 0.02807414 0.9719259     Good
#&gt; 4  4  Good 0.25182703 0.7481730     Good
#&gt; 5  5   Bad 0.75193275 0.2480673      Bad
#&gt; 6  6  Good 0.26230149 0.7376985     Good
</code></pre>

<p>The default thresholds for both classes are 0.5.
But according to the cost matrix we should predict class Good only if we are very sure that Good
is the correct label and therefore increase the threshold for class Good and decrease the
threshold for class Bad.</p>
<h5 id="i-theoretical-thresholding">i. Theoretical thresholding</h5>
<p>The theoretical threshold for the <em>positive</em> class can be calculated from the cost matrix as
<script type="math/tex; mode=display">t^* = \frac{c(+1,-1) - c(-1,-1)}{c(+1,-1) - c(+1,+1) + c(-1,+1) - c(-1,-1)}.</script>
For more details see <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a>.</p>
<p>Below the theoretical threshold for the <a href="http://www.rdocumentation.org/packages/caret/functions/GermanCredit.html">German credit example</a>
is calculated and used to predict class labels.
Since the diagonal of the cost matrix is zero the formula given above simplifies accordingly.</p>
<pre><code class="r">## Calculate the theoretical threshold for the positive class
th = costs[2,1]/(costs[2,1] + costs[1,2])
th
#&gt; [1] 0.1666667
</code></pre>

<p>As you may recall you can change thresholds in <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> either before training by using the
<code>predict.threshold</code> option of <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">makeLearner</a> or after prediction by calling <a href="http://www.rdocumentation.org/packages/mlr/functions/setThreshold.html">setThreshold</a>
on the <a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">Prediction</a> object.</p>
<p>As we already have a prediction we use the <a href="http://www.rdocumentation.org/packages/mlr/functions/setThreshold.html">setThreshold</a> function. It returns an altered
<a href="http://www.rdocumentation.org/packages/mlr/functions/Prediction.html">Prediction</a> object with class predictions for the theoretical threshold.</p>
<pre><code class="r">## Predict class labels according to the theoretical threshold
pred.th = setThreshold(pred, th)
pred.th
#&gt; Prediction: 1000 observations
#&gt; predict.type: prob
#&gt; threshold: Bad=0.17,Good=0.83
#&gt; time: 0.02
#&gt;   id truth   prob.Bad prob.Good response
#&gt; 1  1  Good 0.03525092 0.9647491     Good
#&gt; 2  2   Bad 0.63222363 0.3677764      Bad
#&gt; 3  3  Good 0.02807414 0.9719259     Good
#&gt; 4  4  Good 0.25182703 0.7481730      Bad
#&gt; 5  5   Bad 0.75193275 0.2480673      Bad
#&gt; 6  6  Good 0.26230149 0.7376985      Bad
</code></pre>

<p>In order to calculate the average costs over the entire data set we first need to create a new
performance <a href="http://www.rdocumentation.org/packages/mlr/functions/makeMeasure.html">Measure</a>. This can be done through function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeCostMeasure.html">makeCostMeasure</a>
which requires the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">ClassifTask</a> object and the cost matrix (argument <code>costs</code>).
It is expected that the rows of the cost matrix indicate true and the columns predicted
class labels.</p>
<pre><code class="r">credit.costs = makeCostMeasure(id = &quot;credit.costs&quot;, costs = costs, task = credit.task, best = 0, worst = 5)
credit.costs
#&gt; Name: credit.costs
#&gt; Performance measure: credit.costs
#&gt; Properties: classif,classif.multi,req.pred,req.truth,predtype.response,predtype.prob
#&gt; Minimize: TRUE
#&gt; Best: 0; Worst: 5
#&gt; Aggregated by: test.mean
#&gt; Note:
</code></pre>

<p>Then the average costs can be computed by function <a href="http://www.rdocumentation.org/packages/mlr/functions/performance.html">performance</a>.
Below we compare the average costs and the error rate (<a href="../measures/index.html">mmce</a>) of the learning algorithm
with both default thresholds 0.5 and theoretical thresholds.</p>
<pre><code class="r">## Performance with default thresholds 0.5
performance(pred, measures = list(credit.costs, mmce))
#&gt; credit.costs         mmce 
#&gt;        0.774        0.214

## Performance with theoretical thresholds
performance(pred.th, measures = list(credit.costs, mmce))
#&gt; credit.costs         mmce 
#&gt;        0.478        0.346
</code></pre>

<p>These performance values may be overly optimistic as we used the same data set for training
and prediction, and resampling strategies should be preferred.
In the R-code below we make use of the <code>predict.threshold</code> argument of <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">makeLearner</a> to set
the threshold before doing 3-fold cross-validation.
Note that we create a <a href="http://www.rdocumentation.org/packages/mlr/functions/makeResampleInstance.html">ResampleInstance</a> (<code>rin</code>) for the
<a href="http://www.rdocumentation.org/packages/caret/functions/GermanCredit.html">German credit data</a> that is used throughout the next several code
examples to get comparable performance values.</p>
<pre><code class="r">## Cross-validated performance with theoretical thresholds
rin = makeResampleInstance(&quot;CV&quot;, iters = 3, task = credit.task)
lrn = makeLearner(&quot;classif.multinom&quot;, predict.type = &quot;prob&quot;, predict.threshold = th, trace = FALSE)
r = resample(lrn, credit.task, resampling = rin, measures = list(credit.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: GermanCredit
#&gt; Learner: classif.multinom
#&gt; credit.costs.aggr: 0.56
#&gt; credit.costs.mean: 0.56
#&gt; credit.costs.sd: 0.03
#&gt; mmce.aggr: 0.36
#&gt; mmce.mean: 0.36
#&gt; mmce.sd: 0.02
#&gt; Runtime: 0.368795
</code></pre>

<p>If we are also interested in the cross-validated performance for the default threshold values
we can call <a href="http://www.rdocumentation.org/packages/mlr/functions/setThreshold.html">setThreshold</a> on the <a href="http://www.rdocumentation.org/packages/mlr/functions/ResamplePrediction.html">resampled prediction</a> <code>r$pred</code>.</p>
<pre><code class="r">## Cross-validated performance with default thresholds
performance(setThreshold(r$pred, 0.5), measures = list(credit.costs, mmce))
#&gt; credit.costs         mmce 
#&gt;        0.852        0.248
</code></pre>

<p>Theoretical thresholding is only reliable if the predicted posterior probabilities are correct.
If there are systematic errors the thresholds have to be shifted accordingly.</p>
<p>Useful in this regard is function <a href="http://www.rdocumentation.org/packages/mlr/functions/plotThreshVsPerf.html">plotThreshVsPerf</a> that permits to plot the average costs
as well as any other performance measure versus possible threshold values for the positive
class in [0,1]. The underlying data is generated from <a href="http://www.rdocumentation.org/packages/mlr/functions/generateThreshVsPerfData.html">generateThreshVsPerfData</a>.</p>
<p>The following plot show the cross-validated costs and error rate (<a href="../measures/index.html">mmce</a>).
The theoretical threshold <code>th</code> calculated above is indicated by the vertical line.
As you can see the theoretical threshold seems a bit large.</p>
<pre><code class="r">d = generateThreshVsPerfData(r, measures = list(credit.costs, mmce))
plotThreshVsPerf(d, mark.th = th)
</code></pre>

<p><img alt="plot of chunk unnamed-chunk-9" src="data:image/svg+xml;base64,<?xml version="1.0" encoding="UTF-8"?>
<svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="576pt" height="288pt" viewBox="0 0 576 288" version="1.1">
<defs>
<g>
<symbol overflow="visible" id="glyph0-0">
<path style="stroke:none;" d="M 4.515625 -3.34375 C 4.484375 -3.828125 4.375 -4.140625 4.1875 -4.421875 C 3.84375 -4.890625 3.234375 -5.171875 2.53125 -5.171875 C 1.1875 -5.171875 0.296875 -4.09375 0.296875 -2.421875 C 0.296875 -0.8125 1.15625 0.21875 2.515625 0.21875 C 3.71875 0.21875 4.484375 -0.5 4.578125 -1.734375 L 3.765625 -1.734375 C 3.640625 -0.921875 3.21875 -0.515625 2.546875 -0.515625 C 1.65625 -0.515625 1.125 -1.234375 1.125 -2.421875 C 1.125 -3.6875 1.65625 -4.4375 2.515625 -4.4375 C 3.1875 -4.4375 3.609375 -4.03125 3.71875 -3.34375 Z M 4.515625 -3.34375 "/>
</symbol>
<symbol overflow="visible" id="glyph0-1">
<path style="stroke:none;" d="M 0.65625 -5.03125 L 0.65625 0 L 1.46875 0 L 1.46875 -2.609375 C 1.46875 -3.328125 1.65625 -3.796875 2.03125 -4.078125 C 2.28125 -4.265625 2.515625 -4.3125 3.078125 -4.328125 L 3.078125 -5.140625 C 2.9375 -5.15625 2.875 -5.171875 2.765625 -5.171875 C 2.25 -5.171875 1.859375 -4.859375 1.40625 -4.109375 L 1.40625 -5.03125 Z M 0.65625 -5.03125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-2">
<path style="stroke:none;" d="M 4.921875 -2.25 C 4.921875 -3.015625 4.859375 -3.46875 4.71875 -3.84375 C 4.390625 -4.671875 3.625 -5.171875 2.6875 -5.171875 C 1.28125 -5.171875 0.390625 -4.09375 0.390625 -2.453125 C 0.390625 -0.796875 1.25 0.21875 2.671875 0.21875 C 3.8125 0.21875 4.609375 -0.4375 4.8125 -1.53125 L 4.015625 -1.53125 C 3.796875 -0.859375 3.34375 -0.515625 2.703125 -0.515625 C 2.1875 -0.515625 1.75 -0.75 1.484375 -1.171875 C 1.296875 -1.453125 1.234375 -1.75 1.21875 -2.25 Z M 1.234375 -2.890625 C 1.3125 -3.828125 1.875 -4.4375 2.671875 -4.4375 C 3.46875 -4.4375 4.0625 -3.78125 4.0625 -2.953125 C 4.0625 -2.9375 4.0625 -2.921875 4.0625 -2.890625 Z M 1.234375 -2.890625 "/>
</symbol>
<symbol overflow="visible" id="glyph0-3">
<path style="stroke:none;" d="M 4.75 -7 L 3.953125 -7 L 3.953125 -4.390625 C 3.609375 -4.90625 3.078125 -5.171875 2.40625 -5.171875 C 1.109375 -5.171875 0.25 -4.125 0.25 -2.515625 C 0.25 -0.828125 1.078125 0.21875 2.4375 0.21875 C 3.125 0.21875 3.609375 -0.03125 4.03125 -0.65625 L 4.03125 0 L 4.75 0 Z M 2.546875 -4.421875 C 3.40625 -4.421875 3.953125 -3.65625 3.953125 -2.453125 C 3.953125 -1.296875 3.390625 -0.53125 2.546875 -0.53125 C 1.671875 -0.53125 1.078125 -1.3125 1.078125 -2.46875 C 1.078125 -3.640625 1.671875 -4.421875 2.546875 -4.421875 Z M 2.546875 -4.421875 "/>
</symbol>
<symbol overflow="visible" id="glyph0-4">
<path style="stroke:none;" d="M 1.4375 -5.03125 L 0.640625 -5.03125 L 0.640625 0 L 1.4375 0 Z M 1.4375 -7 L 0.640625 -7 L 0.640625 -5.984375 L 1.4375 -5.984375 Z M 1.4375 -7 "/>
</symbol>
<symbol overflow="visible" id="glyph0-5">
<path style="stroke:none;" d="M 2.4375 -5.03125 L 1.609375 -5.03125 L 1.609375 -6.40625 L 0.8125 -6.40625 L 0.8125 -5.03125 L 0.140625 -5.03125 L 0.140625 -4.375 L 0.8125 -4.375 L 0.8125 -0.578125 C 0.8125 -0.0625 1.15625 0.21875 1.78125 0.21875 C 1.96875 0.21875 2.171875 0.203125 2.4375 0.15625 L 2.4375 -0.515625 C 2.328125 -0.484375 2.203125 -0.484375 2.046875 -0.484375 C 1.703125 -0.484375 1.609375 -0.578125 1.609375 -0.9375 L 1.609375 -4.375 L 2.4375 -4.375 Z M 2.4375 -5.03125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-6">
<path style="stroke:none;" d="M 1.828125 -1 L 0.828125 -1 L 0.828125 0 L 1.828125 0 Z M 1.828125 -1 "/>
</symbol>
<symbol overflow="visible" id="glyph0-7">
<path style="stroke:none;" d="M 2.609375 -5.171875 C 1.203125 -5.171875 0.34375 -4.15625 0.34375 -2.46875 C 0.34375 -0.78125 1.1875 0.21875 2.625 0.21875 C 4.03125 0.21875 4.890625 -0.78125 4.890625 -2.4375 C 4.890625 -4.171875 4.0625 -5.171875 2.609375 -5.171875 Z M 2.625 -4.4375 C 3.515625 -4.4375 4.0625 -3.6875 4.0625 -2.453125 C 4.0625 -1.265625 3.5 -0.515625 2.625 -0.515625 C 1.734375 -0.515625 1.1875 -1.25 1.1875 -2.46875 C 1.1875 -3.6875 1.734375 -4.4375 2.625 -4.4375 Z M 2.625 -4.4375 "/>
</symbol>
<symbol overflow="visible" id="glyph0-8">
<path style="stroke:none;" d="M 4.203125 -3.625 C 4.1875 -4.609375 3.546875 -5.171875 2.375 -5.171875 C 1.203125 -5.171875 0.453125 -4.5625 0.453125 -3.640625 C 0.453125 -2.84375 0.859375 -2.46875 2.046875 -2.1875 L 2.796875 -2 C 3.34375 -1.875 3.5625 -1.671875 3.5625 -1.3125 C 3.5625 -0.828125 3.09375 -0.515625 2.390625 -0.515625 C 1.96875 -0.515625 1.609375 -0.640625 1.40625 -0.859375 C 1.28125 -1 1.21875 -1.140625 1.171875 -1.5 L 0.328125 -1.5 C 0.359375 -0.328125 1.015625 0.21875 2.328125 0.21875 C 3.59375 0.21875 4.40625 -0.40625 4.40625 -1.375 C 4.40625 -2.125 3.984375 -2.53125 2.984375 -2.765625 L 2.21875 -2.953125 C 1.5625 -3.109375 1.28125 -3.3125 1.28125 -3.671875 C 1.28125 -4.140625 1.703125 -4.4375 2.34375 -4.4375 C 3 -4.4375 3.34375 -4.15625 3.359375 -3.625 Z M 4.203125 -3.625 "/>
</symbol>
<symbol overflow="visible" id="glyph0-9">
<path style="stroke:none;" d="M 0.671875 -5.03125 L 0.671875 0 L 1.484375 0 L 1.484375 -3.15625 C 1.484375 -3.890625 2 -4.46875 2.65625 -4.46875 C 3.25 -4.46875 3.59375 -4.109375 3.59375 -3.46875 L 3.59375 0 L 4.390625 0 L 4.390625 -3.15625 C 4.390625 -3.890625 4.921875 -4.46875 5.578125 -4.46875 C 6.15625 -4.46875 6.5 -4.09375 6.5 -3.46875 L 6.5 0 L 7.3125 0 L 7.3125 -3.765625 C 7.3125 -4.671875 6.796875 -5.171875 5.859375 -5.171875 C 5.1875 -5.171875 4.78125 -4.96875 4.3125 -4.40625 C 4.015625 -4.9375 3.609375 -5.171875 2.953125 -5.171875 C 2.28125 -5.171875 1.84375 -4.921875 1.40625 -4.3125 L 1.40625 -5.03125 Z M 0.671875 -5.03125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-10">
<path style="stroke:none;" d="M 2.640625 -6.796875 C 2 -6.796875 1.421875 -6.53125 1.078125 -6.046875 C 0.640625 -5.453125 0.40625 -4.546875 0.40625 -3.296875 C 0.40625 -1 1.1875 0.21875 2.640625 0.21875 C 4.078125 0.21875 4.859375 -1 4.859375 -3.234375 C 4.859375 -4.5625 4.65625 -5.4375 4.203125 -6.046875 C 3.84375 -6.53125 3.28125 -6.796875 2.640625 -6.796875 Z M 2.640625 -6.046875 C 3.546875 -6.046875 4 -5.125 4 -3.3125 C 4 -1.375 3.5625 -0.484375 2.625 -0.484375 C 1.734375 -0.484375 1.28125 -1.421875 1.28125 -3.28125 C 1.28125 -5.140625 1.734375 -6.046875 2.640625 -6.046875 Z M 2.640625 -6.046875 "/>
</symbol>
<symbol overflow="visible" id="glyph0-11">
<path style="stroke:none;" d="M 4.5625 -6.796875 L 1.0625 -6.796875 L 0.546875 -3.09375 L 1.328125 -3.09375 C 1.71875 -3.5625 2.046875 -3.734375 2.578125 -3.734375 C 3.484375 -3.734375 4.0625 -3.109375 4.0625 -2.09375 C 4.0625 -1.125 3.484375 -0.53125 2.578125 -0.53125 C 1.828125 -0.53125 1.375 -0.90625 1.1875 -1.671875 L 0.328125 -1.671875 C 0.453125 -1.109375 0.546875 -0.84375 0.75 -0.59375 C 1.125 -0.078125 1.828125 0.21875 2.59375 0.21875 C 3.96875 0.21875 4.921875 -0.78125 4.921875 -2.21875 C 4.921875 -3.5625 4.03125 -4.484375 2.71875 -4.484375 C 2.25 -4.484375 1.859375 -4.359375 1.46875 -4.0625 L 1.734375 -5.96875 L 4.5625 -5.96875 Z M 4.5625 -6.796875 "/>
</symbol>
<symbol overflow="visible" id="glyph0-12">
<path style="stroke:none;" d="M 4.984375 -6.796875 L 0.4375 -6.796875 L 0.4375 -5.96875 L 4.109375 -5.96875 C 2.5 -3.65625 1.828125 -2.234375 1.328125 0 L 2.21875 0 C 2.59375 -2.171875 3.453125 -4.046875 4.984375 -6.09375 Z M 4.984375 -6.796875 "/>
</symbol>
<symbol overflow="visible" id="glyph0-13">
<path style="stroke:none;" d="M 2.484375 -4.84375 L 2.484375 0 L 3.328125 0 L 3.328125 -6.796875 L 2.765625 -6.796875 C 2.46875 -5.75 2.28125 -5.609375 0.984375 -5.453125 L 0.984375 -4.84375 Z M 2.484375 -4.84375 "/>
</symbol>
<symbol overflow="visible" id="glyph0-14">
<path style="stroke:none;" d="M 4.859375 -0.828125 L 1.28125 -0.828125 C 1.359375 -1.390625 1.671875 -1.75 2.5 -2.234375 L 3.46875 -2.75 C 4.40625 -3.265625 4.90625 -3.96875 4.90625 -4.8125 C 4.90625 -5.375 4.671875 -5.90625 4.265625 -6.265625 C 3.859375 -6.625 3.375 -6.796875 2.71875 -6.796875 C 1.859375 -6.796875 1.21875 -6.5 0.84375 -5.921875 C 0.609375 -5.5625 0.5 -5.125 0.484375 -4.4375 L 1.328125 -4.4375 C 1.359375 -4.90625 1.40625 -5.1875 1.53125 -5.40625 C 1.75 -5.8125 2.1875 -6.0625 2.703125 -6.0625 C 3.46875 -6.0625 4.03125 -5.515625 4.03125 -4.78125 C 4.03125 -4.25 3.71875 -3.796875 3.125 -3.4375 L 2.234375 -2.9375 C 0.8125 -2.140625 0.40625 -1.5 0.328125 0 L 4.859375 0 Z M 4.859375 -0.828125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-15">
<path style="stroke:none;" d="M 2.125 -3.125 L 2.578125 -3.125 C 3.515625 -3.125 3.984375 -2.703125 3.984375 -1.890625 C 3.984375 -1.03125 3.46875 -0.53125 2.578125 -0.53125 C 1.65625 -0.53125 1.203125 -0.984375 1.15625 -1.96875 L 0.3125 -1.96875 C 0.34375 -1.421875 0.4375 -1.078125 0.609375 -0.765625 C 0.953125 -0.109375 1.625 0.21875 2.546875 0.21875 C 3.953125 0.21875 4.859375 -0.609375 4.859375 -1.90625 C 4.859375 -2.765625 4.515625 -3.25 3.703125 -3.515625 C 4.34375 -3.765625 4.65625 -4.25 4.65625 -4.9375 C 4.65625 -6.109375 3.875 -6.796875 2.578125 -6.796875 C 1.203125 -6.796875 0.484375 -6.046875 0.453125 -4.609375 L 1.296875 -4.609375 C 1.3125 -5.015625 1.34375 -5.25 1.453125 -5.453125 C 1.640625 -5.828125 2.0625 -6.0625 2.59375 -6.0625 C 3.34375 -6.0625 3.796875 -5.625 3.796875 -4.90625 C 3.796875 -4.421875 3.609375 -4.140625 3.25 -3.984375 C 3.015625 -3.890625 2.71875 -3.84375 2.125 -3.84375 Z M 2.125 -3.125 "/>
</symbol>
<symbol overflow="visible" id="glyph0-16">
<path style="stroke:none;" d="M 3.140625 -1.625 L 3.140625 0 L 3.984375 0 L 3.984375 -1.625 L 4.984375 -1.625 L 4.984375 -2.390625 L 3.984375 -2.390625 L 3.984375 -6.796875 L 3.359375 -6.796875 L 0.265625 -2.515625 L 0.265625 -1.625 Z M 3.140625 -2.390625 L 1 -2.390625 L 3.140625 -5.359375 Z M 3.140625 -2.390625 "/>
</symbol>
<symbol overflow="visible" id="glyph0-17">
<path style="stroke:none;" d="M 4.78125 -5.03125 C 4.609375 -6.140625 3.890625 -6.796875 2.84375 -6.796875 C 2.09375 -6.796875 1.421875 -6.4375 1.03125 -5.828125 C 0.609375 -5.171875 0.40625 -4.34375 0.40625 -3.09375 C 0.40625 -1.953125 0.578125 -1.234375 0.984375 -0.625 C 1.359375 -0.078125 1.953125 0.21875 2.703125 0.21875 C 3.984375 0.21875 4.921875 -0.734375 4.921875 -2.078125 C 4.921875 -3.34375 4.0625 -4.234375 2.84375 -4.234375 C 2.171875 -4.234375 1.640625 -3.96875 1.28125 -3.46875 C 1.28125 -5.125 1.828125 -6.046875 2.796875 -6.046875 C 3.390625 -6.046875 3.796875 -5.671875 3.9375 -5.03125 Z M 2.734375 -3.484375 C 3.546875 -3.484375 4.0625 -2.921875 4.0625 -2 C 4.0625 -1.15625 3.484375 -0.53125 2.703125 -0.53125 C 1.921875 -0.53125 1.328125 -1.1875 1.328125 -2.046875 C 1.328125 -2.890625 1.90625 -3.484375 2.734375 -3.484375 Z M 2.734375 -3.484375 "/>
</symbol>
<symbol overflow="visible" id="glyph1-0">
<path style="stroke:none;" d="M 3.046875 -6.28125 L 2.015625 -6.28125 L 2.015625 -8.015625 L 1.015625 -8.015625 L 1.015625 -6.28125 L 0.171875 -6.28125 L 0.171875 -5.46875 L 1.015625 -5.46875 L 1.015625 -0.71875 C 1.015625 -0.078125 1.453125 0.28125 2.234375 0.28125 C 2.46875 0.28125 2.71875 0.25 3.046875 0.1875 L 3.046875 -0.640625 C 2.921875 -0.609375 2.765625 -0.59375 2.5625 -0.59375 C 2.140625 -0.59375 2.015625 -0.71875 2.015625 -1.15625 L 2.015625 -5.46875 L 3.046875 -5.46875 Z M 3.046875 -6.28125 "/>
</symbol>
<symbol overflow="visible" id="glyph1-1">
<path style="stroke:none;" d="M 0.84375 -8.75 L 0.84375 0 L 1.84375 0 L 1.84375 -3.46875 C 1.84375 -4.75 2.515625 -5.59375 3.546875 -5.59375 C 3.859375 -5.59375 4.1875 -5.484375 4.421875 -5.296875 C 4.71875 -5.09375 4.84375 -4.796875 4.84375 -4.359375 L 4.84375 0 L 5.828125 0 L 5.828125 -4.75 C 5.828125 -5.8125 5.078125 -6.46875 3.859375 -6.46875 C 2.96875 -6.46875 2.421875 -6.1875 1.84375 -5.421875 L 1.84375 -8.75 Z M 0.84375 -8.75 "/>
</symbol>
<symbol overflow="visible" id="glyph1-2">
<path style="stroke:none;" d="M 0.828125 -6.28125 L 0.828125 0 L 1.84375 0 L 1.84375 -3.265625 C 1.84375 -4.15625 2.0625 -4.75 2.546875 -5.09375 C 2.859375 -5.328125 3.15625 -5.40625 3.859375 -5.40625 L 3.859375 -6.4375 C 3.6875 -6.453125 3.59375 -6.46875 3.46875 -6.46875 C 2.8125 -6.46875 2.328125 -6.078125 1.75 -5.140625 L 1.75 -6.28125 Z M 0.828125 -6.28125 "/>
</symbol>
<symbol overflow="visible" id="glyph1-3">
<path style="stroke:none;" d="M 6.15625 -2.8125 C 6.15625 -3.765625 6.078125 -4.34375 5.90625 -4.8125 C 5.5 -5.84375 4.53125 -6.46875 3.359375 -6.46875 C 1.609375 -6.46875 0.484375 -5.125 0.484375 -3.0625 C 0.484375 -1 1.578125 0.28125 3.34375 0.28125 C 4.78125 0.28125 5.765625 -0.546875 6.03125 -1.90625 L 5.015625 -1.90625 C 4.734375 -1.078125 4.171875 -0.640625 3.375 -0.640625 C 2.734375 -0.640625 2.203125 -0.9375 1.859375 -1.46875 C 1.625 -1.828125 1.53125 -2.1875 1.53125 -2.8125 Z M 1.546875 -3.625 C 1.625 -4.78125 2.34375 -5.546875 3.34375 -5.546875 C 4.328125 -5.546875 5.09375 -4.734375 5.09375 -3.703125 C 5.09375 -3.671875 5.09375 -3.640625 5.078125 -3.625 Z M 1.546875 -3.625 "/>
</symbol>
<symbol overflow="visible" id="glyph1-4">
<path style="stroke:none;" d="M 5.25 -4.53125 C 5.25 -5.765625 4.421875 -6.46875 2.96875 -6.46875 C 1.515625 -6.46875 0.5625 -5.71875 0.5625 -4.546875 C 0.5625 -3.5625 1.0625 -3.09375 2.5625 -2.734375 L 3.484375 -2.515625 C 4.1875 -2.34375 4.46875 -2.09375 4.46875 -1.625 C 4.46875 -1.046875 3.875 -0.640625 3 -0.640625 C 2.453125 -0.640625 2 -0.796875 1.75 -1.0625 C 1.59375 -1.25 1.53125 -1.421875 1.46875 -1.875 L 0.40625 -1.875 C 0.453125 -0.421875 1.265625 0.28125 2.921875 0.28125 C 4.5 0.28125 5.515625 -0.5 5.515625 -1.71875 C 5.515625 -2.65625 4.984375 -3.171875 3.734375 -3.46875 L 2.765625 -3.703125 C 1.953125 -3.890625 1.609375 -4.15625 1.609375 -4.59375 C 1.609375 -5.171875 2.125 -5.546875 2.9375 -5.546875 C 3.75 -5.546875 4.171875 -5.203125 4.203125 -4.53125 Z M 5.25 -4.53125 "/>
</symbol>
<symbol overflow="visible" id="glyph1-5">
<path style="stroke:none;" d="M 3.265625 -6.46875 C 1.5 -6.46875 0.4375 -5.203125 0.4375 -3.09375 C 0.4375 -0.984375 1.484375 0.28125 3.28125 0.28125 C 5.046875 0.28125 6.125 -0.984375 6.125 -3.046875 C 6.125 -5.21875 5.078125 -6.46875 3.265625 -6.46875 Z M 3.28125 -5.546875 C 4.40625 -5.546875 5.078125 -4.625 5.078125 -3.0625 C 5.078125 -1.578125 4.375 -0.640625 3.28125 -0.640625 C 2.15625 -0.640625 1.46875 -1.578125 1.46875 -3.09375 C 1.46875 -4.609375 2.15625 -5.546875 3.28125 -5.546875 Z M 3.28125 -5.546875 "/>
</symbol>
<symbol overflow="visible" id="glyph1-6">
<path style="stroke:none;" d="M 1.828125 -8.75 L 0.8125 -8.75 L 0.8125 0 L 1.828125 0 Z M 1.828125 -8.75 "/>
</symbol>
<symbol overflow="visible" id="glyph1-7">
<path style="stroke:none;" d="M 5.9375 -8.75 L 4.9375 -8.75 L 4.9375 -5.5 C 4.53125 -6.125 3.859375 -6.46875 3.015625 -6.46875 C 1.375 -6.46875 0.3125 -5.15625 0.3125 -3.15625 C 0.3125 -1.03125 1.359375 0.28125 3.046875 0.28125 C 3.90625 0.28125 4.515625 -0.046875 5.046875 -0.828125 L 5.046875 0 L 5.9375 0 Z M 3.1875 -5.53125 C 4.265625 -5.53125 4.9375 -4.578125 4.9375 -3.078125 C 4.9375 -1.625 4.25 -0.65625 3.1875 -0.65625 C 2.09375 -0.65625 1.359375 -1.625 1.359375 -3.09375 C 1.359375 -4.5625 2.09375 -5.53125 3.1875 -5.53125 Z M 3.1875 -5.53125 "/>
</symbol>
<symbol overflow="visible" id="glyph2-0">
<path style="stroke:none;" d="M 2.609375 -0.640625 L 2.609375 -1.65625 L -0.65625 -1.65625 C -0.015625 -2.1875 0.28125 -2.765625 0.28125 -3.59375 C 0.28125 -5.203125 -1.03125 -6.28125 -3.03125 -6.28125 C -5.140625 -6.28125 -6.46875 -5.25 -6.46875 -3.578125 C -6.46875 -2.71875 -6.078125 -2.046875 -5.34375 -1.578125 L -6.28125 -1.578125 L -6.28125 -0.640625 Z M -5.53125 -3.40625 C -5.53125 -4.515625 -4.5625 -5.234375 -3.0625 -5.234375 C -1.625 -5.234375 -0.65625 -4.5 -0.65625 -3.40625 C -0.65625 -2.359375 -1.625 -1.65625 -3.09375 -1.65625 C -4.578125 -1.65625 -5.53125 -2.359375 -5.53125 -3.40625 Z M -5.53125 -3.40625 "/>
</symbol>
<symbol overflow="visible" id="glyph2-1">
<path style="stroke:none;" d="M -2.8125 -6.15625 C -3.765625 -6.15625 -4.34375 -6.078125 -4.8125 -5.90625 C -5.84375 -5.5 -6.46875 -4.53125 -6.46875 -3.359375 C -6.46875 -1.609375 -5.125 -0.484375 -3.0625 -0.484375 C -1 -0.484375 0.28125 -1.578125 0.28125 -3.34375 C 0.28125 -4.78125 -0.546875 -5.765625 -1.90625 -6.03125 L -1.90625 -5.015625 C -1.078125 -4.734375 -0.640625 -4.171875 -0.640625 -3.375 C -0.640625 -2.734375 -0.9375 -2.203125 -1.46875 -1.859375 C -1.828125 -1.625 -2.1875 -1.53125 -2.8125 -1.53125 Z M -3.625 -1.546875 C -4.78125 -1.625 -5.546875 -2.34375 -5.546875 -3.34375 C -5.546875 -4.328125 -4.734375 -5.09375 -3.703125 -5.09375 C -3.671875 -5.09375 -3.640625 -5.09375 -3.625 -5.078125 Z M -3.625 -1.546875 "/>
</symbol>
<symbol overflow="visible" id="glyph2-2">
<path style="stroke:none;" d="M -6.28125 -0.828125 L 0 -0.828125 L 0 -1.84375 L -3.265625 -1.84375 C -4.15625 -1.84375 -4.75 -2.0625 -5.09375 -2.546875 C -5.328125 -2.859375 -5.40625 -3.15625 -5.40625 -3.859375 L -6.4375 -3.859375 C -6.453125 -3.6875 -6.46875 -3.59375 -6.46875 -3.46875 C -6.46875 -2.8125 -6.078125 -2.328125 -5.140625 -1.75 L -6.28125 -1.75 Z M -6.28125 -0.828125 "/>
</symbol>
<symbol overflow="visible" id="glyph2-3">
<path style="stroke:none;" d="M -6.28125 -3.09375 L -6.28125 -2.046875 L -7.265625 -2.046875 C -7.6875 -2.046875 -7.90625 -2.296875 -7.90625 -2.75 C -7.90625 -2.828125 -7.90625 -2.875 -7.890625 -3.09375 L -8.71875 -3.09375 C -8.765625 -2.875 -8.78125 -2.734375 -8.78125 -2.53125 C -8.78125 -1.609375 -8.25 -1.0625 -7.359375 -1.0625 L -6.28125 -1.0625 L -6.28125 -0.21875 L -5.46875 -0.21875 L -5.46875 -1.0625 L 0 -1.0625 L 0 -2.046875 L -5.46875 -2.046875 L -5.46875 -3.09375 Z M -6.28125 -3.09375 "/>
</symbol>
</g>
<clipPath id="clip1">
  <path d="M 49.945312 28.78125 L 294.480469 28.78125 L 294.480469 251.335938 L 49.945312 251.335938 Z M 49.945312 28.78125 "/>
</clipPath>
<clipPath id="clip2">
  <path d="M 318.066406 28.78125 L 562.601562 28.78125 L 562.601562 251.335938 L 318.066406 251.335938 Z M 318.066406 28.78125 "/>
</clipPath>
</defs>
<g id="surface34">
<rect x="0" y="0" width="576" height="288" style="fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;"/>
<rect x="0" y="0" width="576" height="288" style="fill:rgb(100%,100%,100%);fill-opacity:1;stroke:none;"/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:round;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 0 288 L 576 288 L 576 0 L 0 0 Z M 0 288 "/>
<g clip-path="url(#clip1)" clip-rule="nonzero">
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(89.803922%,89.803922%,89.803922%);fill-opacity:1;" d="M 49.945312 250.332031 L 293.480469 250.332031 L 293.480469 28.777344 L 49.945312 28.777344 Z M 49.945312 250.332031 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 216.507812 L 293.480469 216.507812 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 165.75 L 293.480469 165.75 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 114.988281 L 293.480469 114.988281 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 64.230469 L 293.480469 64.230469 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 88.691406 250.332031 L 88.691406 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 144.039062 250.332031 L 144.039062 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 199.386719 250.332031 L 199.386719 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 254.734375 250.332031 L 254.734375 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 241.886719 L 293.480469 241.886719 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 191.128906 L 293.480469 191.128906 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 140.367188 L 293.480469 140.367188 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 89.609375 L 293.480469 89.609375 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 49.945312 38.851562 L 293.480469 38.851562 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 61.015625 250.332031 L 61.015625 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 116.363281 250.332031 L 116.363281 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 171.714844 250.332031 L 171.714844 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 227.0625 250.332031 L 227.0625 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 282.410156 250.332031 L 282.410156 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:1;" d="M 61.015625 201.28125 L 63.253906 205.339844 L 65.488281 212.039062 L 67.726562 216.101562 L 69.960938 222.394531 L 72.199219 227.675781 L 74.433594 228.894531 L 76.671875 232.75 L 78.90625 237.21875 L 81.144531 238.03125 L 83.378906 238.433594 L 85.617188 240.261719 L 87.851562 238.839844 L 90.089844 238.636719 L 92.324219 235.390625 L 94.5625 232.34375 L 96.796875 231.53125 L 99.035156 230.3125 L 101.269531 228.894531 L 103.507812 230.921875 L 105.742188 228.894531 L 107.980469 228.285156 L 110.214844 227.066406 L 112.453125 223.613281 L 114.6875 222.394531 L 116.925781 221.582031 L 119.160156 222.394531 L 121.398438 220.769531 L 123.632812 218.742188 L 125.867188 216.914062 L 128.105469 216.507812 L 130.339844 215.695312 L 132.578125 211.835938 L 134.8125 211.429688 L 137.050781 209.808594 L 139.285156 207.371094 L 141.523438 202.496094 L 143.757812 202.296875 L 145.996094 201.890625 L 148.230469 200.0625 L 150.46875 197.421875 L 152.703125 196 L 154.941406 190.316406 L 157.175781 188.082031 L 159.414062 183.414062 L 161.648438 179.148438 L 163.886719 177.726562 L 166.121094 172.449219 L 168.359375 170.417969 L 170.59375 170.214844 L 172.832031 170.417969 L 175.066406 165.546875 L 177.304688 160.875 L 179.539062 159.453125 L 181.777344 158.4375 L 184.011719 154.175781 L 186.25 151.332031 L 188.484375 149.097656 L 190.722656 144.023438 L 192.957031 141.585938 L 195.195312 140.164062 L 197.429688 134.480469 L 199.667969 128.796875 L 201.902344 128.1875 L 204.140625 124.9375 L 206.375 121.285156 L 208.613281 121.488281 L 210.847656 118.847656 L 213.085938 117.628906 L 215.320312 116.003906 L 217.558594 115.800781 L 219.792969 113.160156 L 222.03125 110.320312 L 224.265625 102.605469 L 226.503906 99.152344 L 228.738281 92.65625 L 230.976562 89.609375 L 233.210938 86.5625 L 235.449219 83.316406 L 237.683594 83.722656 L 239.921875 81.691406 L 242.15625 77.832031 L 244.394531 77.019531 L 246.628906 75.398438 L 248.867188 69.507812 L 251.101562 64.433594 L 253.339844 61.589844 L 255.574219 58.75 L 257.8125 57.734375 L 260.046875 56.71875 L 262.285156 55.90625 L 264.519531 51.234375 L 266.757812 47.378906 L 268.992188 46.769531 L 271.230469 43.722656 L 273.464844 42.910156 L 275.703125 40.882812 L 277.9375 38.851562 L 282.410156 38.851562 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 97.914062 250.332031 L 97.914062 28.78125 "/>
</g>
<g clip-path="url(#clip2)" clip-rule="nonzero">
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(89.803922%,89.803922%,89.803922%);fill-opacity:1;" d="M 318.066406 250.332031 L 561.601562 250.332031 L 561.601562 28.777344 L 318.066406 28.777344 Z M 318.066406 250.332031 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 238.050781 L 561.601562 238.050781 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 193.78125 L 561.601562 193.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 149.515625 L 561.601562 149.515625 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 105.25 L 561.601562 105.25 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 60.984375 L 561.601562 60.984375 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 356.8125 250.332031 L 356.8125 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 412.160156 250.332031 L 412.160156 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 467.507812 250.332031 L 467.507812 28.78125 "/>
<path style="fill:none;stroke-width:0.531496;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(94.901961%,94.901961%,94.901961%);stroke-opacity:1;stroke-miterlimit:10;" d="M 522.855469 250.332031 L 522.855469 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 215.917969 L 561.601562 215.917969 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 171.648438 L 561.601562 171.648438 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 127.382812 L 561.601562 127.382812 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 83.117188 L 561.601562 83.117188 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 318.066406 38.851562 L 561.601562 38.851562 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 329.136719 250.332031 L 329.136719 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 384.484375 250.332031 L 384.484375 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 439.832031 250.332031 L 439.832031 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 495.183594 250.332031 L 495.183594 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(100%,100%,100%);stroke-opacity:1;stroke-miterlimit:10;" d="M 550.53125 250.332031 L 550.53125 28.78125 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:1;" d="M 329.136719 38.851562 L 331.371094 51.246094 L 333.609375 67.625 L 335.84375 80.019531 L 338.082031 97.28125 L 340.316406 110.5625 L 342.554688 122.070312 L 344.789062 134.023438 L 347.027344 145.53125 L 349.261719 152.617188 L 351.5 158.8125 L 353.734375 166.335938 L 355.972656 173.863281 L 358.207031 178.734375 L 360.445312 180.503906 L 362.679688 180.945312 L 364.917969 186.257812 L 367.152344 190.683594 L 369.390625 191.128906 L 371.625 197.324219 L 373.863281 199.980469 L 376.097656 202.195312 L 378.335938 206.621094 L 380.570312 207.949219 L 382.808594 210.605469 L 385.042969 215.917969 L 387.28125 219.457031 L 389.515625 221.226562 L 391.753906 222.113281 L 393.988281 225.210938 L 396.226562 227.867188 L 398.460938 229.640625 L 400.699219 228.3125 L 402.933594 229.195312 L 405.171875 229.195312 L 407.40625 230.96875 L 409.644531 229.195312 L 411.878906 230.523438 L 414.117188 231.410156 L 416.351562 232.738281 L 418.589844 234.066406 L 420.824219 236.277344 L 423.0625 238.050781 L 425.296875 238.492188 L 427.535156 237.164062 L 429.769531 236.722656 L 432.007812 237.164062 L 434.242188 236.277344 L 436.480469 237.164062 L 438.714844 238.492188 L 440.953125 238.933594 L 443.1875 238.933594 L 445.425781 237.605469 L 447.660156 239.820312 L 449.898438 239.378906 L 452.132812 238.933594 L 454.371094 239.820312 L 456.605469 240.261719 L 458.84375 238.050781 L 461.078125 238.050781 L 463.316406 238.492188 L 465.550781 236.722656 L 467.785156 234.949219 L 470.023438 235.394531 L 472.257812 235.394531 L 474.496094 234.507812 L 476.730469 234.949219 L 478.96875 236.277344 L 481.203125 237.164062 L 483.441406 237.164062 L 485.675781 238.492188 L 487.914062 238.050781 L 490.148438 237.164062 L 492.386719 234.507812 L 494.621094 234.066406 L 496.859375 232.292969 L 499.09375 230.96875 L 501.332031 229.640625 L 503.566406 229.640625 L 505.804688 230.523438 L 508.039062 229.640625 L 510.277344 228.3125 L 514.75 228.3125 L 516.984375 226.097656 L 519.222656 223.882812 L 521.457031 223 L 523.695312 222.113281 L 525.929688 221.671875 L 528.167969 221.226562 L 530.402344 221.226562 L 532.640625 219.898438 L 534.875 218.570312 L 537.113281 219.015625 L 539.347656 217.6875 L 541.585938 217.6875 L 543.820312 216.800781 L 546.058594 215.917969 L 550.53125 215.917969 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(0%,0%,0%);stroke-opacity:1;stroke-miterlimit:10;" d="M 366.035156 250.332031 L 366.035156 28.78125 "/>
</g>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(80%,80%,80%);fill-opacity:1;" d="M 49.945312 28.78125 L 293.480469 28.78125 L 293.480469 14.402344 L 49.945312 14.402344 Z M 49.945312 28.78125 "/>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-0" x="147.214844" y="24.237305"/>
  <use xlink:href="#glyph0-1" x="152.011719" y="24.237305"/>
  <use xlink:href="#glyph0-2" x="155.206055" y="24.237305"/>
  <use xlink:href="#glyph0-3" x="160.540039" y="24.237305"/>
  <use xlink:href="#glyph0-4" x="165.874023" y="24.237305"/>
  <use xlink:href="#glyph0-5" x="168.003906" y="24.237305"/>
  <use xlink:href="#glyph0-6" x="170.670898" y="24.237305"/>
  <use xlink:href="#glyph0-0" x="173.337891" y="24.237305"/>
  <use xlink:href="#glyph0-7" x="178.134766" y="24.237305"/>
  <use xlink:href="#glyph0-8" x="183.46875" y="24.237305"/>
  <use xlink:href="#glyph0-5" x="188.265625" y="24.237305"/>
  <use xlink:href="#glyph0-8" x="190.932617" y="24.237305"/>
</g>
<path style=" stroke:none;fill-rule:nonzero;fill:rgb(80%,80%,80%);fill-opacity:1;" d="M 318.066406 28.78125 L 561.601562 28.78125 L 561.601562 14.402344 L 318.066406 14.402344 Z M 318.066406 28.78125 "/>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph0-9" x="426.332031" y="24.237305"/>
  <use xlink:href="#glyph0-9" x="434.323242" y="24.237305"/>
  <use xlink:href="#glyph0-0" x="442.314453" y="24.237305"/>
  <use xlink:href="#glyph0-2" x="447.111328" y="24.237305"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="23.859375" y="244.53418"/>
  <use xlink:href="#glyph0-6" x="29.193359" y="244.53418"/>
  <use xlink:href="#glyph0-11" x="31.860352" y="244.53418"/>
  <use xlink:href="#glyph0-10" x="37.194336" y="244.53418"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="23.859375" y="193.776367"/>
  <use xlink:href="#glyph0-6" x="29.193359" y="193.776367"/>
  <use xlink:href="#glyph0-12" x="31.860352" y="193.776367"/>
  <use xlink:href="#glyph0-11" x="37.194336" y="193.776367"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-13" x="23.859375" y="143.014648"/>
  <use xlink:href="#glyph0-6" x="29.193359" y="143.014648"/>
  <use xlink:href="#glyph0-10" x="31.860352" y="143.014648"/>
  <use xlink:href="#glyph0-10" x="37.194336" y="143.014648"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-13" x="23.859375" y="92.256836"/>
  <use xlink:href="#glyph0-6" x="29.193359" y="92.256836"/>
  <use xlink:href="#glyph0-14" x="31.860352" y="92.256836"/>
  <use xlink:href="#glyph0-11" x="37.194336" y="92.256836"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-13" x="23.859375" y="41.499023"/>
  <use xlink:href="#glyph0-6" x="29.193359" y="41.499023"/>
  <use xlink:href="#glyph0-11" x="31.860352" y="41.499023"/>
  <use xlink:href="#glyph0-10" x="37.194336" y="41.499023"/>
</g>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 45.695312 241.886719 L 49.945312 241.886719 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 45.695312 191.128906 L 49.945312 191.128906 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 45.695312 140.367188 L 49.945312 140.367188 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 45.695312 89.609375 L 49.945312 89.609375 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 45.695312 38.851562 L 49.945312 38.851562 "/>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="296.980469" y="218.56543"/>
  <use xlink:href="#glyph0-6" x="302.314453" y="218.56543"/>
  <use xlink:href="#glyph0-15" x="304.981445" y="218.56543"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="296.980469" y="174.295898"/>
  <use xlink:href="#glyph0-6" x="302.314453" y="174.295898"/>
  <use xlink:href="#glyph0-16" x="304.981445" y="174.295898"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="296.980469" y="130.030273"/>
  <use xlink:href="#glyph0-6" x="302.314453" y="130.030273"/>
  <use xlink:href="#glyph0-11" x="304.981445" y="130.030273"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="296.980469" y="85.764648"/>
  <use xlink:href="#glyph0-6" x="302.314453" y="85.764648"/>
  <use xlink:href="#glyph0-17" x="304.981445" y="85.764648"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="296.980469" y="41.499023"/>
  <use xlink:href="#glyph0-6" x="302.314453" y="41.499023"/>
  <use xlink:href="#glyph0-12" x="304.981445" y="41.499023"/>
</g>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 313.816406 215.917969 L 318.066406 215.917969 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 313.816406 171.648438 L 318.066406 171.648438 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 313.816406 127.382812 L 318.066406 127.382812 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 313.816406 83.117188 L 318.066406 83.117188 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 313.816406 38.851562 L 318.066406 38.851562 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 61.015625 254.585938 L 61.015625 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 116.363281 254.585938 L 116.363281 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 171.714844 254.585938 L 171.714844 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 227.0625 254.585938 L 227.0625 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 282.410156 254.585938 L 282.410156 250.332031 "/>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="51.515625" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="56.849609" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="59.516602" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="64.850586" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="106.863281" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="112.197266" y="263.569336"/>
  <use xlink:href="#glyph0-14" x="114.864258" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="120.198242" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="162.214844" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="167.548828" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="170.21582" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="175.549805" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="217.5625" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="222.896484" y="263.569336"/>
  <use xlink:href="#glyph0-12" x="225.563477" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="230.897461" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-13" x="272.910156" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="278.244141" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="280.911133" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="286.245117" y="263.569336"/>
</g>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 329.136719 254.585938 L 329.136719 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 384.484375 254.585938 L 384.484375 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 439.832031 254.585938 L 439.832031 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 495.183594 254.585938 L 495.183594 250.332031 "/>
<path style="fill:none;stroke-width:1.062992;stroke-linecap:butt;stroke-linejoin:round;stroke:rgb(49.803922%,49.803922%,49.803922%);stroke-opacity:1;stroke-miterlimit:10;" d="M 550.53125 254.585938 L 550.53125 250.332031 "/>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="319.636719" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="324.970703" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="327.637695" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="332.97168" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="374.984375" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="380.318359" y="263.569336"/>
  <use xlink:href="#glyph0-14" x="382.985352" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="388.319336" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="430.332031" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="435.666016" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="438.333008" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="443.666992" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-10" x="485.683594" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="491.017578" y="263.569336"/>
  <use xlink:href="#glyph0-12" x="493.68457" y="263.569336"/>
  <use xlink:href="#glyph0-11" x="499.018555" y="263.569336"/>
</g>
<g style="fill:rgb(49.803922%,49.803922%,49.803922%);fill-opacity:1;">
  <use xlink:href="#glyph0-13" x="541.03125" y="263.569336"/>
  <use xlink:href="#glyph0-6" x="546.365234" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="549.032227" y="263.569336"/>
  <use xlink:href="#glyph0-10" x="554.366211" y="263.569336"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph1-0" x="280.773438" y="276.634766"/>
  <use xlink:href="#glyph1-1" x="284.109375" y="276.634766"/>
  <use xlink:href="#glyph1-2" x="290.78125" y="276.634766"/>
  <use xlink:href="#glyph1-3" x="294.777344" y="276.634766"/>
  <use xlink:href="#glyph1-4" x="301.449219" y="276.634766"/>
  <use xlink:href="#glyph1-1" x="307.449219" y="276.634766"/>
  <use xlink:href="#glyph1-5" x="314.121094" y="276.634766"/>
  <use xlink:href="#glyph1-6" x="320.792969" y="276.634766"/>
  <use xlink:href="#glyph1-7" x="323.457031" y="276.634766"/>
</g>
<g style="fill:rgb(0%,0%,0%);fill-opacity:1;">
  <use xlink:href="#glyph2-0" x="19.236328" y="150.058594"/>
  <use xlink:href="#glyph2-1" x="19.236328" y="143.386719"/>
  <use xlink:href="#glyph2-2" x="19.236328" y="136.714844"/>
  <use xlink:href="#glyph2-3" x="19.236328" y="132.71875"/>
</g>
</g>
</svg>
" /> </p>
<h5 id="ii-empirical-thresholding">ii. Empirical thresholding</h5>
<p>In <em>empirical thresholding</em> (see <a href="http://sun0.cs.uca.edu/~ssheng/papers/AAAI06a.pdf">Sheng and Ling (2006)</a>)
cost-optimal threshold values for a given learning method are selected based on the training data.
In contrast to <em>theoretical thresholding</em> it suffices if the estimated posterior probabilities
are order-correct.</p>
<p>In order to determine optimal threshold values you can use <a href="http://www.rdocumentation.org/packages/mlr/">mlr</a>'s function <a href="http://www.rdocumentation.org/packages/mlr/functions/tuneThreshold.html">tuneThreshold</a>.
As tuning the threshold on the complete training data set can lead to overfitting, resampling
strategies should be used.
Below we perform 3-fold cross-validation and use <a href="http://www.rdocumentation.org/packages/mlr/functions/tuneThreshold.html">tuneThreshold</a> to calculate threshold values
with lowest average costs over the 3 test data sets.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, predict.type = &quot;prob&quot;, trace = FALSE)

## 3-fold cross-validation
r = resample(lrn, credit.task, resampling = rin, measures = list(credit.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: GermanCredit
#&gt; Learner: classif.multinom
#&gt; credit.costs.aggr: 0.85
#&gt; credit.costs.mean: 0.85
#&gt; credit.costs.sd: 0.17
#&gt; mmce.aggr: 0.25
#&gt; mmce.mean: 0.25
#&gt; mmce.sd: 0.03
#&gt; Runtime: 0.380153

## Tune the threshold based on the predicted probabilities on the 3 test data sets
tune.res = tuneThreshold(pred = r$pred, measure = credit.costs)
tune.res
#&gt; $th
#&gt; [1] 0.1110669
#&gt; 
#&gt; $perf
#&gt; credit.costs 
#&gt;        0.508
</code></pre>

<p><a href="http://www.rdocumentation.org/packages/mlr/functions/tuneThreshold.html">tuneThreshold</a> returns the optimal threshold value for the positive class and the corresponding
performance.
As expected the tuned threshold is smaller than the theoretical threshold.</p>
<h4 id="2-rebalancing">2. Rebalancing</h4>
<p>In order to minimize the average costs, observations from the less costly class should be
given higher importance during training.
This can be achieved by <em>weighting</em> the classes if the classification method under consideration
accepts class or observations weights.
Alternatively, <em>over- and undersampling</em> techniques can be used.</p>
<h5 id="i-weighting">i. Weighting</h5>
<p>Similar to <em>theoretical thresholding</em>, <em>theoretical weights</em> can be calculated from the
cost matrix.
If <script type="math/tex">t</script> indicates the target threshold and <script type="math/tex">t_0</script> the original threshold for the positive class the
proportion of observations in the positive class has to be multiplied by
<script type="math/tex; mode=display">\frac{1-t}{t} \frac{t_0}{1-t_0}.</script>
Alternatively, the proportion of observations in the negative class can be multiplied by
the inverse.
A proof is given by <a href="http://www.cs.iastate.edu/~honavar/elkan.pdf">Elkan (2001)</a>.</p>
<p>In most cases, the original threshold <script type="math/tex">t_0</script> is 0.5 and thus the second factor vanishes.
If additionally the target threshold <script type="math/tex">t</script> equals the theoretical threshold <script type="math/tex">t^*</script> the
proportion of observations in the positive class has to be multiplied by
<script type="math/tex; mode=display">\frac{1-t^*}{t^*} = \frac{c(-1,+1) - c(+1,+1)}{c(+1,-1) - c(-1,-1)}.</script>
</p>
<p>Function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a> allows to assign class weights to <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>s.
Naturally, this is only possible for methods with either a 'class weights' or an 'observation weights' argument.
(Have a look at the <a href="../integrated_learners/index.html">table of integrated learners</a> to see which methods
support observation weights.)</p>
<p>Function <a href="http://www.rdocumentation.org/packages/nnet/functions/multinom.html">multinom</a> accepts observation weights.
The weight given to all observations from the positive class is passed via argument <code>wcw.weight</code>.
Observations from the negative class automatically receive weight 1.</p>
<pre><code class="r">## Weight corresponding to theoretical treshold
w = (1 - th)/th
w
#&gt; [1] 5

## Weighted learner
lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeWeightedClassesWrapper(lrn, wcw.weight = w)
lrn
#&gt; Learner weightedclasses.classif.multinom from package nnet
#&gt; Type: classif
#&gt; Name: ; Short name: 
#&gt; Class: WeightedClassesWrapper
#&gt; Properties: numerics,factors,prob,twoclass,multiclass
#&gt; Predict-Type: response
#&gt; Hyperparameters: trace=FALSE,wcw.weight=5
</code></pre>

<p>The theoretical threshold corresponds to a weight of 5 for the positive class.
Below the wrapped learner is used to get predictions. Moreover, its cross-validated performance is
calculated.</p>
<pre><code class="r">mod = train(lrn, credit.task)
pred = predict(mod, task = credit.task)
pred
#&gt; Prediction: 1000 observations
#&gt; predict.type: response
#&gt; threshold: 
#&gt; time: 0.02
#&gt;   id truth response
#&gt; 1  1  Good     Good
#&gt; 2  2   Bad      Bad
#&gt; 3  3  Good     Good
#&gt; 4  4  Good      Bad
#&gt; 5  5   Bad      Bad
#&gt; 6  6  Good      Bad

r = resample(lrn, credit.task, rin, measures = list(credit.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: GermanCredit
#&gt; Learner: weightedclasses.classif.multinom
#&gt; credit.costs.aggr: 0.53
#&gt; credit.costs.mean: 0.53
#&gt; credit.costs.sd: 0.04
#&gt; mmce.aggr: 0.35
#&gt; mmce.mean: 0.35
#&gt; mmce.sd: 0.02
#&gt; Runtime: 0.415755
</code></pre>

<p>Some classification methods as the support vector machine (<a href="http://www.rdocumentation.org/packages/kernlab/functions/ksvm.html">ksvm</a>) in package <a href="http://www.rdocumentation.org/packages/kernlab/">kernlab</a>
support class weights.
When generating the wrapped <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> you have to pass the name of the relevant
learner parameter (<code>"class.weights"</code> for <a href="../&amp;kernlab:::ksvm">ksvm</a>) via argument <code>wcw.param</code>
in addition to the weight.</p>
<pre><code class="r">lrn = makeWeightedClassesWrapper(&quot;classif.ksvm&quot;, wcw.param = &quot;class.weights&quot;, wcw.weight = w)
mod = train(lrn, credit.task)
pred = predict(mod, task = credit.task)
pred
#&gt; Prediction: 1000 observations
#&gt; predict.type: response
#&gt; threshold: 
#&gt; time: 0.10
#&gt;   id truth response
#&gt; 1  1  Good     Good
#&gt; 2  2   Bad      Bad
#&gt; 3  3  Good     Good
#&gt; 4  4  Good      Bad
#&gt; 5  5   Bad      Bad
#&gt; 6  6  Good     Good

r = resample(lrn, credit.task, rin, measures = list(credit.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: GermanCredit
#&gt; Learner: weightedclasses.classif.ksvm
#&gt; credit.costs.aggr: 0.58
#&gt; credit.costs.mean: 0.58
#&gt; credit.costs.sd: 0.04
#&gt; mmce.aggr: 0.31
#&gt; mmce.mean: 0.31
#&gt; mmce.sd: 0.02
#&gt; Runtime: 0.624578
</code></pre>

<p>Just like the theoretical threshold, the theoretical weights may not always be suitable,
therefore you can tune the weight for the positive class as shown in the following example.
Calculating the theoretical weight beforehand may help to narrow down the search interval.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeWeightedClassesWrapper(lrn)
ps = makeParamSet(makeDiscreteParam(&quot;wcw.weight&quot;, seq(4, 12, 0.5)))
ctrl = makeTuneControlGrid()
tune.res = tuneParams(lrn, credit.task, resampling = rin, par.set = ps,
  measures = list(credit.costs, mmce), control = ctrl, show.info = FALSE)
tune.res
#&gt; Tune result:
#&gt; Op. pars: wcw.weight=7.5
#&gt; credit.costs.test.mean=0.501,mmce.test.mean=0.381
as.data.frame(tune.res$opt.path)[1:3]
#&gt;    wcw.weight credit.costs.test.mean mmce.test.mean
#&gt; 1           4              0.5650291      0.3330127
#&gt; 2         4.5              0.5550251      0.3430167
#&gt; 3           5              0.5260320      0.3460197
#&gt; 4         5.5              0.5130070      0.3530147
#&gt; 5           6              0.5160100      0.3640137
#&gt; 6         6.5              0.5160160      0.3720157
#&gt; 7           7              0.5040250      0.3760167
#&gt; 8         7.5              0.5010040      0.3810038
#&gt; 9           8              0.5100130      0.3900128
#&gt; 10        8.5              0.5100070      0.3940108
#&gt; 11          9              0.5110080      0.4030078
#&gt; 12        9.5              0.5160130      0.4080128
#&gt; 13         10              0.5260140      0.4180138
#&gt; 14       10.5              0.5240060      0.4200098
#&gt; 15         11              0.5319991      0.4280029
#&gt; 16       11.5              0.5289901      0.4330019
#&gt; 17         12              0.5249801      0.4369999
</code></pre>

<h5 id="ii-over-and-undersampling">ii. Over- and undersampling</h5>
<p>If the <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> supports neither observation nor class weights the proportions
of the classes in the training data can be changed by over- or undersampling.</p>
<p>In the <a href="http://www.rdocumentation.org/packages/caret/functions/GermanCredit.html">GermanCredit data set</a> the positive class Bad should receive
a theoretical weight of about <code>w = (1 - th)/th = 5</code>.
This can be achieved by oversampling class Bad with a <code>rate</code> of 5 (see also the documentation
page of function <a href="http://www.rdocumentation.org/packages/mlr/functions/oversample.html">oversample</a>).</p>
<pre><code class="r">credit.task.over = oversample(credit.task, rate = w)
lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
mod = train(lrn, credit.task.over)
pred = predict(mod, task = credit.task)
performance(pred, measures = list(credit.costs, mmce))
#&gt; credit.costs         mmce 
#&gt;        0.440        0.328
</code></pre>

<p>Note that in the example above the learner was trained on the oversampled task <code>credit.task.over</code>.
In order to get the training performance on the original task predictions were calculated for <code>credit.task</code>.</p>
<p>We usually prefer resampled performance values, but simply calling <a href="http://www.rdocumentation.org/packages/mlr/functions/resample.html">resample</a> on the oversampled
task does not work since predictions have to be done for the original task.
The solution is to create a wrapped <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a> via function
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeUndersampleWrapper.html">makeOversampleWrapper</a>.
Internally, <a href="http://www.rdocumentation.org/packages/mlr/functions/oversample.html">oversample</a> is called before training, but predictions are done on the original task.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeOversampleWrapper(lrn, osw.rate = w)
lrn
#&gt; Learner classif.multinom.oversampled from package mlr,nnet
#&gt; Type: classif
#&gt; Name: ; Short name: 
#&gt; Class: OversampleWrapper
#&gt; Properties: numerics,factors,weights,prob,twoclass,multiclass
#&gt; Predict-Type: response
#&gt; Hyperparameters: trace=FALSE,osw.rate=5

r = resample(lrn, credit.task, rin, measures = list(credit.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: GermanCredit
#&gt; Learner: classif.multinom.oversampled
#&gt; credit.costs.aggr: 0.56
#&gt; credit.costs.mean: 0.56
#&gt; credit.costs.sd: 0.05
#&gt; mmce.aggr: 0.35
#&gt; mmce.mean: 0.35
#&gt; mmce.sd: 0.02
#&gt; Runtime: 0.801767
</code></pre>

<p>Of course, we can also tune the oversampling rate.
For this purpose we again have to create an <a href="http://www.rdocumentation.org/packages/mlr/functions/makeUndersampleWrapper.html">OversampleWrapper</a>.
Optimal values for parameter <code>osw.rate</code> can be obtained using function <a href="http://www.rdocumentation.org/packages/mlr/functions/tuneParams.html">tuneParams</a>.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeOversampleWrapper(lrn)
ps = makeParamSet(makeDiscreteParam(&quot;osw.rate&quot;, seq(3, 7, 0.25)))
ctrl = makeTuneControlGrid()
tune.res = tuneParams(lrn, credit.task, rin, par.set = ps, measures = list(credit.costs, mmce),
  control = ctrl, show.info = FALSE)
tune.res
#&gt; Tune result:
#&gt; Op. pars: osw.rate=6
#&gt; credit.costs.test.mean=0.496,mmce.test.mean=0.352
</code></pre>

<h3 id="multi-class-problems">Multi-class problems</h3>
<p>We consider the <a href="http://www.rdocumentation.org/packages/mlbench/functions/mlbench.waveform.html">waveform</a> data set from package <a href="http://www.rdocumentation.org/packages/mlbench/">mlbench</a> and
add an artificial cost matrix:</p>
<table>
<thead>
<tr>
<th></th>
<th align="center"></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr>
<td>true\pred.</td>
<td align="center">1</td>
<td align="center">2</td>
<td align="center">3</td>
</tr>
<tr>
<td>1</td>
<td align="center">0</td>
<td align="center">30</td>
<td align="center">80</td>
</tr>
<tr>
<td>2</td>
<td align="center">5</td>
<td align="center">0</td>
<td align="center">4</td>
</tr>
<tr>
<td>3</td>
<td align="center">10</td>
<td align="center">8</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<p>We start by creating the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a>, the cost matrix and the corresponding performance measure.</p>
<pre><code class="r">## Task
df = mlbench::mlbench.waveform(500)
wf.task = makeClassifTask(id = &quot;waveform&quot;, data = as.data.frame(df), target = &quot;classes&quot;)

## Cost matrix
costs = matrix(c(0, 5, 10, 30, 0, 8, 80, 4, 0), 3)
colnames(costs) = rownames(costs) = getTaskDescription(wf.task)$class.levels

## Performance measure
wf.costs = makeCostMeasure(id = &quot;wf.costs&quot;, costs = costs, task = wf.task, best = 0,
  worst = 10)
</code></pre>

<p>In the multi-class case, both, <em>thresholding</em> and <em>rebalancing</em> correspond to cost matrices
of a certain structure where <script type="math/tex">c(k,l) = c(l)</script> for <script type="math/tex">k</script>, <script type="math/tex">l = 1, \ldots, K</script>, <script type="math/tex">k \neq l</script>.
This condition means that the cost of misclassifying an observation is independent of the
predicted class label
(see <a href="http://homes.cs.washington.edu/~pedrod/papers/kdd99.pdf">Domingos (1999)</a>).
Given a cost matrix of this type, theoretical thresholds and weights can be derived
in a similar manner as in the binary case.
Obviously, the cost matrix given above does not have this special structure.</p>
<h4 id="1-thresholding_1">1. Thresholding</h4>
<p>Given a vector of positive threshold values as long as the number of classes <script type="math/tex">K</script>, the predicted
probabilities for all classes are adjusted by dividing them by the corresponding threshold value.
Then the class with the highest adjusted probability is predicted.
This way, as in the binary case, classes with a low threshold are predicted more easily than
classes with a larger threshold.</p>
<p>Again this can be done by function <a href="http://www.rdocumentation.org/packages/mlr/functions/setThreshold.html">setThreshold</a> as shown in the following example (or
alternatively by the <code>predict.threshold</code> option of <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">makeLearner</a>).
Note that the threshold vector needs to have names that correspond to the class labels.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.rpart&quot;, predict.type = &quot;prob&quot;)
rin = makeResampleInstance(&quot;CV&quot;, iters = 3, task = wf.task)
r = resample(lrn, wf.task, rin, measures = list(wf.costs, mmce), show.info = FALSE)
r
#&gt; Resample Result
#&gt; Task: waveform
#&gt; Learner: classif.rpart
#&gt; wf.costs.aggr: 8.26
#&gt; wf.costs.mean: 8.26
#&gt; wf.costs.sd: 2.85
#&gt; mmce.aggr: 0.34
#&gt; mmce.mean: 0.34
#&gt; mmce.sd: 0.04
#&gt; Runtime: 0.0895629

## Calculate thresholds as 1/(average costs of true classes)
th = 2/rowSums(costs)
names(th) = getTaskDescription(wf.task)$class.levels
th
#&gt;          1          2          3 
#&gt; 0.01818182 0.22222222 0.11111111

pred.th = setThreshold(r$pred, threshold = th)
performance(pred.th, measures = list(wf.costs, mmce))
#&gt; wf.costs     mmce 
#&gt;    5.668    0.480
</code></pre>

<p>The threshold vector <code>th</code> in the above example is chosen according to the average costs
of the true classes 55, 4.5 and 9.
More exactly, <code>th</code> corresponds to an artificial cost matrix of the structure mentioned
above with off-diagonal elements <script type="math/tex">c(2,1) = c(3,1) = 55</script>, <script type="math/tex">c(1,2) = c(3,2) = 4.5</script> and
<script type="math/tex">c(1,3) = c(2,3) = 9</script>.
This threshold vector may be not optimal but leads to smaller total costs on the data set than
the default.</p>
<h5 id="ii-empirical-thresholding_1">ii. Empirical thresholding</h5>
<p>As in the binary case it is possible to tune the threshold vector using function <a href="http://www.rdocumentation.org/packages/mlr/functions/tuneThreshold.html">tuneThreshold</a>.
Since the scaling of the threshold vector does not change the predicted class labels
<a href="http://www.rdocumentation.org/packages/mlr/functions/tuneThreshold.html">tuneThreshold</a> returns threshold values that lie in [0,1] and sum to unity.</p>
<pre><code class="r">tune.res = tuneThreshold(pred = r$pred, measure = wf.costs)
tune.res
#&gt; $th
#&gt;             1             2             3 
#&gt; -1.657070e-09  3.914654e-01  6.085346e-01 
#&gt; 
#&gt; $perf
#&gt; [1] 5.05
</code></pre>

<p>For comparison we show the standardized version of the theoretically motivated threshold
vector chosen above.</p>
<pre><code class="r">th/sum(th)
#&gt;          1          2          3 
#&gt; 0.05172414 0.63218391 0.31609195
</code></pre>

<h4 id="2-rebalancing_1">2. Rebalancing</h4>
<h5 id="i-weighting_1">i. Weighting</h5>
<p>In the multi-class case you have to pass a vector of weights as long as the number of classes
<script type="math/tex">K</script> to function <a href="http://www.rdocumentation.org/packages/mlr/functions/makeWeightedClassesWrapper.html">makeWeightedClassesWrapper</a>.
The weight vector can be tuned using function <a href="http://www.rdocumentation.org/packages/mlr/functions/tuneParams.html">tuneParams</a>.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeWeightedClassesWrapper(lrn)

ps = makeParamSet(makeNumericVectorParam(&quot;wcw.weight&quot;, len = 3, lower = 0, upper = 1))
ctrl = makeTuneControlRandom()

tune.res = tuneParams(lrn, wf.task, resampling = rin, par.set = ps,
  measures = list(wf.costs, mmce), control = ctrl, show.info = FALSE)
tune.res
#&gt; Tune result:
#&gt; Op. pars: wcw.weight=0.673,0.12,0.0204
#&gt; wf.costs.test.mean=2.63,mmce.test.mean=0.222
</code></pre>

<h2 id="example-dependent-misclassification-costs">Example-dependent misclassification costs</h2>
<p>In case of example-dependent costs we have to create a special <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a> via function
<a href="http://www.rdocumentation.org/packages/mlr/functions/makeCostSensTask.html">makeCostSensTask</a>.
For this purpose the feature values <script type="math/tex">x</script> and an <script type="math/tex">n \times K</script>
<code>cost</code> matrix that contains
the cost vectors for all <script type="math/tex">n</script> examples in the data set are required.</p>
<p>We use the <a href="http://www.rdocumentation.org/packages/datasets/functions/iris.html">iris</a> data and generate an artificial cost matrix.</p>
<pre><code class="r">df = iris
cost = matrix(runif(150 * 3, 0, 2000), 150) * (1 - diag(3))[df$Species,] + runif(150, 0, 10)
colnames(cost) = levels(iris$Species)
rownames(cost) = rownames(iris)
df$Species = NULL

costsens.task = makeCostSensTask(id = &quot;iris&quot;, data = df, cost = cost)
costsens.task
#&gt; Supervised task: iris
#&gt; Type: costsens
#&gt; Observations: 150
#&gt; Features:
#&gt; numerics  factors  ordered 
#&gt;        4        0        0 
#&gt; Missings: FALSE
#&gt; Has blocking: FALSE
#&gt; Classes: 3
#&gt; setosa, versicolor, virginica
</code></pre>

<p><a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> provides several <a href="../wrapper/index.html">wrappers</a> to turn regular classification or regression methods
into <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>s that can deal with example-dependent costs.</p>
<ul>
<li><a href="http://www.rdocumentation.org/packages/mlr/functions/makeCostSensClassifWrapper.html">makeCostSensClassifWrapper</a> (wraps a classification <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>):
  This is a naive approach where the costs are coerced into class labels by choosing the
  class label with minimum cost for each example. Then a regular classification method is
  used.</li>
<li><a href="http://www.rdocumentation.org/packages/mlr/functions/makeCostSensRegrWrapper.html">makeCostSensRegrWrapper</a> (wraps a regression <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>):
  An individual regression model is fitted for the costs of each class.
  In the prediction step first the costs are predicted for all classes and then the class with
  the lowest predicted costs is selected.</li>
<li><a href="http://www.rdocumentation.org/packages/mlr/functions/makeCostSensWeightedPairsWrapper.html">makeCostSensWeightedPairsWrapper</a> (wraps a classification <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>):
  This is also known as <em>cost-sensitive one-vs-one</em> (CS-OVO) and the most sophisticated of
  the currently supported methods.
  For each pair of classes, a binary classifier is fitted.
  For each observation the class label is defined as the element of the pair with minimal costs.
  During fitting, the observations are weighted with the absolute difference in costs.
  Prediction is performed by simple voting.</li>
</ul>
<p>In the following example we use the third method. We create the wrapped <a href="http://www.rdocumentation.org/packages/mlr/functions/makeLearner.html">Learner</a>
and train it on the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">CostSensTask</a> defined above.</p>
<pre><code class="r">lrn = makeLearner(&quot;classif.multinom&quot;, trace = FALSE)
lrn = makeCostSensWeightedPairsWrapper(lrn)
lrn
#&gt; Learner costsens.classif.multinom from package nnet
#&gt; Type: costsens
#&gt; Name: ; Short name: 
#&gt; Class: CostSensWeightedPairsWrapper
#&gt; Properties: numerics,factors,twoclass,multiclass
#&gt; Predict-Type: response
#&gt; Hyperparameters: trace=FALSE

mod = train(lrn, costsens.task)
mod
#&gt; Model for learner.id=costsens.classif.multinom; learner.class=CostSensWeightedPairsWrapper
#&gt; Trained on: task.id = iris; obs = 150; features = 4
#&gt; Hyperparameters: trace=FALSE
</code></pre>

<p>The models corresponding to the individual pairs can be accessed by function
<a href="http://www.rdocumentation.org/packages/mlr/functions/getHomogeneousEnsembleModels.html">getHomogeneousEnsembleModels</a>.</p>
<pre><code class="r">getHomogeneousEnsembleModels(mod)
#&gt; [[1]]
#&gt; Model for learner.id=classif.multinom; learner.class=classif.multinom
#&gt; Trained on: task.id = feats; obs = 150; features = 4
#&gt; Hyperparameters: trace=FALSE
#&gt; 
#&gt; [[2]]
#&gt; Model for learner.id=classif.multinom; learner.class=classif.multinom
#&gt; Trained on: task.id = feats; obs = 150; features = 4
#&gt; Hyperparameters: trace=FALSE
#&gt; 
#&gt; [[3]]
#&gt; Model for learner.id=classif.multinom; learner.class=classif.multinom
#&gt; Trained on: task.id = feats; obs = 150; features = 4
#&gt; Hyperparameters: trace=FALSE
</code></pre>

<p><a href="http://www.rdocumentation.org/packages/mlr/">mlr</a> provides some performance measures for example-specific cost-sensitive classification.
In the following example we calculate the mean costs of the predicted class labels
(<a href="../measures/index.html">meancosts</a>) and the misclassification penalty (<a href="../measures/index.html">mcp</a>).
The latter measure is the average difference between the costs caused by the predicted
class labels, i.e., <a href="../measures/index.html">meancosts</a>, and the costs resulting from choosing the
class with lowest cost for each observation.
In order to compute these measures the costs for the test observations are required and
therefore the <a href="http://www.rdocumentation.org/packages/mlr/functions/Task.html">Task</a> has to be passed to <a href="http://www.rdocumentation.org/packages/mlr/functions/performance.html">performance</a>.</p>
<pre><code class="r">pred = predict(mod, task = costsens.task)
pred
#&gt; Prediction: 150 observations
#&gt; predict.type: response
#&gt; threshold: 
#&gt; time: 0.06
#&gt;   id response
#&gt; 1  1   setosa
#&gt; 2  2   setosa
#&gt; 3  3   setosa
#&gt; 4  4   setosa
#&gt; 5  5   setosa
#&gt; 6  6   setosa

performance(pred, measures = list(meancosts, mcp), task = costsens.task)
#&gt; meancosts       mcp 
#&gt;  144.8978  139.8698
</code></pre></div>
            
        </div>

        <footer class="col-md-12">
            <hr>
            
            <p>Documentation built with <a href="http://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>

        <script src="../js/jquery-1.10.2.min.js"></script>
        <script src="../js/bootstrap-3.0.3.min.js"></script>
        <script src="../js/highlight.pack.js"></script>
        <script>var base_url = '..';</script>
        <script data-main="../mkdocs/js/search.js" src="../mkdocs/js/require.js"></script>
        <script src="../js/base.js"></script>
        <script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
            <div class="modal-dialog">
                <div class="modal-content">
                    <div class="modal-header">
                        <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                        <h4 class="modal-title" id="exampleModalLabel">Search</h4>
                    </div>
                    <div class="modal-body">
                        <p>
                            From here you can search these documents. Enter
                            your search terms below.
                        </p>
                        <form role="form">
                            <div class="form-group">
                                <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query">
                            </div>
                        </form>
                        <div id="mkdocs-search-results"></div>
                    </div>
                    <div class="modal-footer">
                    </div>
                </div>
            </div>
        </div>

    </body>
</html>
